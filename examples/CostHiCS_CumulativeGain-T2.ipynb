{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T23:14:32.846160Z",
     "start_time": "2017-07-18T23:14:32.417952Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_wHiCS: 10 datasets, each 100 independent features, 40 of them useful  \n",
    "2_wRaR: 10 datasets, each 30 independent features, 20 of them useful, 70 dependent features  \n",
    "3_wRaR: 10 datasets, each 100 independent features, 50 of them useful, 100 dependent features  \n",
    "5_wrar: 1 dataset, 40 independent features, 25 of them useful, 20 dependent  \n",
    "6_wrar: 3 datasets, 40 independent, 30 useful, 40 dependent  \n",
    "7_wrar: 4 datasets, 40 independent, 30 useful, 40 dependent   \n",
    "8_wrar: 4 datasets, each 30 independent features, 20 of them useful, 70 dependent features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T00:31:03.912965Z",
     "start_time": "2017-07-19T00:31:00.235147Z"
    }
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "datas = []\n",
    "for i in range(1, 4):\n",
    "    file = open('../data/10_wrar/10_wrar_' + str(i) + '.arff', 'r')\n",
    "    dataset = arff.load(file)\n",
    "    file.close()\n",
    "    data = pd.DataFrame(dataset['data'])\n",
    "    data[100] = data[100].astype(np.float32)\n",
    "    data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    datas.append(data)\n",
    "target = str(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:20:57.792010Z",
     "start_time": "2017-07-19T01:20:57.786757Z"
    }
   },
   "outputs": [],
   "source": [
    "data = datas[1] # pd.concat(datas).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:14:51.568729Z",
     "start_time": "2017-07-19T01:14:51.558194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44653955346044644"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(np.unique(data[target], return_counts=True)[1]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T16:50:52.889691Z",
     "start_time": "2017-07-18T16:50:37.546155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/5_wrar.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data[60] = data[60].astype(np.float32)\n",
    "data.rename(columns=lambda c: str(c), inplace=True)\n",
    "target = str(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:46:10.398852Z",
     "start_time": "2017-07-19T01:35:13.287952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated cost matrix:\n",
      "         0.0       1.0       2.0      3.0        4.0       5.0        6.0  \\\n",
      "0  11.764706  6.199628  4.106776  4.22833  23.310023  22.83105  41.666667   \n",
      "\n",
      "         7.0       8.0        9.0  \n",
      "0  29.069767  8.591065  81.967213  \n",
      "Overall cost matrix:\n",
      "         0.0       1.0       2.0      3.0        4.0       5.0        6.0  \\\n",
      "0  11.764706  6.199628  4.106776  4.22833  23.310023  22.83105  41.666667   \n",
      "\n",
      "         7.0       8.0        9.0  \n",
      "0  29.069767  8.591065  81.967213  \n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'84': 0.21698886098340173, '33': 1.1019020550119053e-08, '80': 0.18278239975704344, '16': 1.1019020550119053e-08, '4': 0.5848320680796163, '57': 0.46830569075542516, '47': 0.0042952459263725946, '39': 0.073451028480874786, '40': 1.1019020550119053e-08, '0': 0.30155742419300119, '88': 1.1019020550119053e-08, '58': 0.36711315832749208, '81': 0.18069230340977985, '76': 0.25217019950415526, '45': 1.1019020550119053e-08, '27': 1.1019020550119053e-08, '63': 0.51086463536154381, '9': 0.58487248427729488, '29': 1.1022796692072664e-08, '44': 0.083154745327932669, '65': 0.24472817831722787, '98': 0.34302954899921662, '8': 0.4847221932412592, '26': 1.1019020550119053e-08, '21': 0.062576749976094928, '93': 0.0017108905314611161, '79': 0.32445144842831125, '13': 1.1022796692072664e-08, '18': 0.11367395337603818, '17': 0.089974672845221898, '96': 0.18310618978470347, '54': 1.1019020550119053e-08, '52': 1.1019020550119053e-08, '42': 0.14983502108939459, '2': 0.4953999792942318, '1': 0.32300971487380586, '59': 0.30550331252665269, '61': 0.25147235187263006, '64': 0.38888275226696861, '5': 0.078710102347665581, '20': 0.00048334064355722256, '90': 0.30183129676205811, '38': 0.46831442532363093, '6': 0.10570395543876009, '87': 0.034606083208230339, '71': 0.30817493689514053, '77': 1.1019020550119053e-08, '60': 0.19514600798722109, '3': 0.41638714322527248, '67': 0.21698886098341116, '72': 0.0099180472610633612, '95': 0.15381831640226287, '34': 1.1019020550119053e-08, '83': 0.11367395337603818, '53': 0.35170151796098786, '37': 0.22844465739370576, '35': 0.38377378255222905, '68': 0.1627760919508798, '62': 0.025677365678936193, '12': 1.1019020550119053e-08, '22': 0.54224504084666458, '85': 0.1135494826709767, '49': 0.051785433096361515, '48': 0.0032169609290383177, '28': 0.27525920455461766, '7': 0.18562451510972056, '86': 0.086139862467425915, '24': 0.088182012789624564, '15': 1.1019020550119053e-08, '99': 0.16837238675669003, '55': 0.39546381528461932, '14': 0.19505180936400998, '50': 0.33630978154666902, '46': 0.48741081604076997, '23': 0.033057703890383199, '32': 1.1019020550119053e-08, '11': 0.01713113171821181, '10': 1.1019020550119053e-08, '75': 0.1627760919508798, '78': 0.044322420944513635, '82': 0.11390999238850567, '91': 0.52352852942137618, '74': 0.00036360519526726273, '56': 1.1019020550119053e-08, '43': 0.30696453808337409, '41': 0.35170151796099225, '70': 0.25217019950416114, '51': 1.1019020550119053e-08, '66': 0.089777239271431747, '92': 0.56316298674121279, '97': 0.3433668620323056, '94': 0.051777197038444848, '25': 0.27085589586329967, '89': 1.1019020550119053e-08, '69': 0.075477951028111639, '30': 1.1019020550119053e-08, '31': 0.48931856596176104, '73': 0.65979039585633859, '36': 0.075477951028111639, '19': 0.010276771052424237})\n",
      "Redundancy: 100.00%    \n",
      "1. 73 with a score of 0.7944685945983263\n",
      "2. 9 with a score of 0.7378099133226723\n",
      "3. 4 with a score of 0.7376059001398225\n",
      "4. 92 with a score of 0.7201791351621547\n",
      "5. 22 with a score of 0.7026940992031997\n",
      "6. 91 with a score of 0.6869459231860717\n",
      "7. 63 with a score of 0.6759227977381863\n",
      "8. 2 with a score of 0.6622268086461597\n",
      "9. 31 with a score of 0.6568533321707924\n",
      "10. 46 with a score of 0.6549751499208898\n",
      "11. 8 with a score of 0.6526821015139845\n",
      "12. 57 with a score of 0.6376638969988769\n",
      "13. 38 with a score of 0.6376516171139526\n",
      "14. 3 with a score of 0.5878200579497986\n",
      "15. 55 with a score of 0.5665274739907666\n",
      "16. 64 with a score of 0.5597770432301367\n",
      "17. 35 with a score of 0.5544953757584787\n",
      "18. 58 with a score of 0.5368424075238122\n",
      "19. 41 with a score of 0.5202207794180137\n",
      "20. 53 with a score of 0.520216710122491\n",
      "21. 97 with a score of 0.5109600395926593\n",
      "22. 98 with a score of 0.510619174561512\n",
      "23. 50 with a score of 0.5031609744854905\n",
      "24. 79 with a score of 0.48963302259820213\n",
      "25. 1 with a score of 0.4881568910204796\n",
      "26. 71 with a score of 0.4709757935471598\n",
      "27. 43 with a score of 0.4696151371742136\n",
      "28. 59 with a score of 0.46781540565718344\n",
      "29. 90 with a score of 0.46352932246950834\n",
      "30. 0 with a score of 0.4632998699045557\n",
      "31. 28 with a score of 0.43157759563791376\n",
      "32. 25 with a score of 0.42609915687892613\n",
      "33. 76 with a score of 0.40256985259823097\n",
      "34. 70 with a score of 0.4025633371472402\n",
      "35. 61 with a score of 0.40176920992425097\n",
      "36. 65 with a score of 0.3931453397069656\n",
      "37. 37 with a score of 0.3718253157597656\n",
      "38. 67 with a score of 0.35651365380962535\n",
      "39. 84 with a score of 0.3564313639083055\n",
      "40. 60 with a score of 0.32649009300434023\n",
      "41. 14 with a score of 0.3263598482879023\n",
      "42. 7 with a score of 0.31299607947516295\n",
      "43. 96 with a score of 0.30941416689080076\n",
      "44. 80 with a score of 0.30896566393629926\n",
      "45. 81 with a score of 0.30600069847861183\n",
      "46. 99 with a score of 0.288150860982789\n",
      "47. 68 with a score of 0.27993092085972215\n",
      "48. 75 with a score of 0.279886496158013\n",
      "49. 95 with a score of 0.26655042501771825\n",
      "50. 42 with a score of 0.26057072769354445\n",
      "51. 82 with a score of 0.20449117058295704\n",
      "52. 18 with a score of 0.20411930673510242\n",
      "53. 83 with a score of 0.2041017557518343\n",
      "54. 85 with a score of 0.20391069299789305\n",
      "55. 6 with a score of 0.19117304873742025\n",
      "56. 17 with a score of 0.16507724118479292\n",
      "57. 66 with a score of 0.1647412106278363\n",
      "58. 24 with a score of 0.16205336907598883\n",
      "59. 86 with a score of 0.15858411348805393\n",
      "60. 44 with a score of 0.15352937542135014\n",
      "61. 5 with a score of 0.14592127264058502\n",
      "62. 36 with a score of 0.14035054634078625\n",
      "63. 69 with a score of 0.14034046790872884\n",
      "64. 39 with a score of 0.1368422048062838\n",
      "65. 21 with a score of 0.11777343657061823\n",
      "66. 49 with a score of 0.09846745077371381\n",
      "67. 94 with a score of 0.09845032780989295\n",
      "68. 78 with a score of 0.08487585290908395\n",
      "69. 87 with a score of 0.06689503629326383\n",
      "70. 23 with a score of 0.06399824828463256\n",
      "71. 62 with a score of 0.05006793483355956\n",
      "72. 11 with a score of 0.03368433421768766\n",
      "73. 19 with a score of 0.020344164096285495\n",
      "74. 72 with a score of 0.019640947316364708\n",
      "75. 47 with a score of 0.00855370266659352\n",
      "76. 48 with a score of 0.0064132740876930066\n",
      "77. 93 with a score of 0.003415930928905826\n",
      "78. 20 with a score of 0.0009662137437422866\n",
      "79. 74 with a score of 0.0007269456377769581\n",
      "80. 13 with a score of 2.204559314094181e-08\n",
      "81. 29 with a score of 2.204559314090773e-08\n",
      "82. 10 with a score of 2.203804085740048e-08\n",
      "83. 15 with a score of 2.2038040857330037e-08\n",
      "84. 26 with a score of 2.2038040857317884e-08\n",
      "85. 30 with a score of 2.2038040857264415e-08\n",
      "86. 40 with a score of 2.203804085724253e-08\n",
      "87. 34 with a score of 2.203804085723524e-08\n",
      "88. 52 with a score of 2.203804085722794e-08\n",
      "89. 88 with a score of 2.203804085722551e-08\n",
      "90. 56 with a score of 2.203804085718416e-08\n",
      "91. 12 with a score of 2.203804085718173e-08\n",
      "92. 33 with a score of 2.203804085717443e-08\n",
      "93. 54 with a score of 2.2038040857169564e-08\n",
      "94. 32 with a score of 2.203804085715983e-08\n",
      "95. 51 with a score of 2.2038040857140364e-08\n",
      "96. 16 with a score of 2.203804085710142e-08\n",
      "97. 27 with a score of 2.2038040857057593e-08\n",
      "98. 89 with a score of 2.2038040857016188e-08\n",
      "99. 77 with a score of 2.2038040856979643e-08\n",
      "100. 45 with a score of 2.2038040856955275e-08\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'84': 7.218263084381016e-11, '33': 0.13526655381875394, '80': 0.5491874873695155, '16': 0.34000210883176685, '4': 0.1623972773440503, '57': 0.03785664893453861, '47': 0.14323506982341444, '39': 0.07528820487457734, '40': 1.0612466377200466e-07, '0': 7.218263084381016e-11, '88': 0.09424180857220675, '58': 0.24770168618113894, '81': 7.22151519072878e-11, '76': 7.450137351455037e-11, '45': 3.7828395700807167e-07, '27': 0.35276936891257876, '63': 7.218263084381016e-11, '9': 7.218263084381016e-11, '29': 7.401057246757507e-11, '44': 0.2148843726994856, '65': 0.4346193546595111, '98': 7.218263084381016e-11, '8': 0.7850214941012654, '26': 7.158389952865385e-11, '21': 0.16261216470888723, '93': 7.22151519072878e-11, '79': 7.218263084381016e-11, '13': 0.2648496323696509, '18': 7.218263084381016e-11, '17': 0.1762508694413398, '96': 7.218263084381016e-11, '54': 7.154313198371964e-11, '52': 0.14323506982341297, '42': 7.218263084381016e-11, '2': 0.03785664689891675, '1': 0.30194162425712673, '59': 7.311413445331501e-11, '61': 0.06281545943129203, '64': 0.03785664689891704, '5': 7.218263084381016e-11, '20': 7.218263084381016e-11, '90': 1.2301693556973786e-07, '38': 7.218263084381016e-11, '6': 0.24770168618113894, '87': 7.218263084381016e-11, '71': 0.24510890249088987, '77': 7.218263084381016e-11, '60': 7.218263084381016e-11, '3': 7.218263084381016e-11, '67': 1.0, '72': 0.3019416259948914, '95': 7.218263084381016e-11, '34': 0.16200569146745436, '83': 0.278971546551573, '53': 7.218263084381016e-11, '37': 0.13526655381875397, '35': 0.021454656727722506, '68': 7.000045862901105e-11, '62': 7.275996341942236e-11, '12': 0.2789717991908837, '22': 0.2820787731930021, '85': 7.218263084381016e-11, '49': 0.16239753317394073, '48': 7.218263084381016e-11, '28': 0.14323506982341289, '7': 7.055009958600833e-11, '86': 0.29589120412519365, '24': 7.358996119802762e-11, '15': 7.218263084381016e-11, '99': 7.358996119802762e-11, '55': 0.021454504726631476, '14': 0.3021564694549535, '50': 0.16239727734408363, '46': 7.218263084381016e-11, '23': 7.338681114351916e-11, '32': 7.218263084381016e-11, '11': 7.218263084381016e-11, '10': 0.26484960906062793, '75': 0.09622107991936207, '78': 0.69075589974115, '82': 0.491382921422167, '91': 7.218263084381016e-11, '74': 0.037856705724732015, '56': 7.218823508627855e-11, '43': 7.158389952865385e-11, '41': 7.218263084381016e-11, '70': 0.45370949839894154, '51': 7.358996119803231e-11, '66': 0.4995159703235205, '92': 7.218263084381016e-11, '97': 0.739800128379632, '94': 1.0647992270648932e-07, '25': 0.24770169115688295, '89': 0.5779234799230123, '69': 0.3404478734575686, '30': 7.358996119803231e-11, '31': 0.30057994248763215, '73': 0.16200568628086423, '36': 7.108592352544683e-11, '19': 7.218263084381016e-11})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy: 100.00%    \n",
      "1. 67 with a score of 0.9994897397672813\n",
      "2. 8 with a score of 0.8792092567825354\n",
      "3. 97 with a score of 0.8495771885031183\n",
      "4. 78 with a score of 0.8160771309178457\n",
      "5. 89 with a score of 0.73153798396463\n",
      "6. 80 with a score of 0.7086786928303663\n",
      "7. 66 with a score of 0.6659319496570231\n",
      "8. 82 with a score of 0.6584103692195681\n",
      "9. 70 with a score of 0.6238718679790438\n",
      "10. 65 with a score of 0.6056024403817243\n",
      "11. 27 with a score of 0.521363502314585\n",
      "12. 69 with a score of 0.5077184925673326\n",
      "13. 16 with a score of 0.5073207031890353\n",
      "14. 14 with a score of 0.46387488331088683\n",
      "15. 1 with a score of 0.46374132036820803\n",
      "16. 72 with a score of 0.4636551005723144\n",
      "17. 31 with a score of 0.4620843951615249\n",
      "18. 86 with a score of 0.4564234571146668\n",
      "19. 22 with a score of 0.4399045532128012\n",
      "20. 12 with a score of 0.43613624352285313\n",
      "21. 83 with a score of 0.43609111668254186\n",
      "22. 13 with a score of 0.41870891170161906\n",
      "23. 10 with a score of 0.41870537008058956\n",
      "24. 25 with a score of 0.3969541151062535\n",
      "25. 6 with a score of 0.3969438397756612\n",
      "26. 58 with a score of 0.3969398896123991\n",
      "27. 71 with a score of 0.3936030645794746\n",
      "28. 44 with a score of 0.3536669790429063\n",
      "29. 17 with a score of 0.2996262563418064\n",
      "30. 21 with a score of 0.2796755394027452\n",
      "31. 49 with a score of 0.27936234230110163\n",
      "32. 4 with a score of 0.2793525698161568\n",
      "33. 50 with a score of 0.2793474798007903\n",
      "34. 34 with a score of 0.2787909461935067\n",
      "35. 73 with a score of 0.2787745708988899\n",
      "36. 28 with a score of 0.25053796432688585\n",
      "37. 47 with a score of 0.2505313553008395\n",
      "38. 52 with a score of 0.250516239822324\n",
      "39. 33 with a score of 0.23826594216488267\n",
      "40. 37 with a score of 0.23825370322115938\n",
      "41. 75 with a score of 0.17550987794496373\n",
      "42. 88 with a score of 0.17223186042802505\n",
      "43. 39 with a score of 0.14002116777783558\n",
      "44. 61 with a score of 0.11819737612635065\n",
      "45. 64 with a score of 0.0729482342759523\n",
      "46. 57 with a score of 0.07294789124451072\n",
      "47. 2 with a score of 0.07294722027697631\n",
      "48. 74 with a score of 0.07294610101756839\n",
      "49. 35 with a score of 0.04200683483807028\n",
      "50. 55 with a score of 0.042006561182654834\n",
      "51. 45 with a score of 7.565676275236601e-07\n",
      "52. 90 with a score of 2.46033840818569e-07\n",
      "53. 94 with a score of 2.1295982269272868e-07\n",
      "54. 40 with a score of 2.1224930499070604e-07\n",
      "55. 76 with a score of 1.490027470179805e-10\n",
      "56. 29 with a score of 1.480211449241791e-10\n",
      "57. 51 with a score of 1.4717992238522165e-10\n",
      "58. 30 with a score of 1.4717992238521827e-10\n",
      "59. 99 with a score of 1.471799223852105e-10\n",
      "60. 24 with a score of 1.4717992238520488e-10\n",
      "61. 23 with a score of 1.4677362227625156e-10\n",
      "62. 59 with a score of 1.4622826889592892e-10\n",
      "63. 62 with a score of 1.4551992682824176e-10\n",
      "64. 81 with a score of 1.444303038041321e-10\n",
      "65. 93 with a score of 1.4443030380412015e-10\n",
      "66. 56 with a score of 1.4437647016212586e-10\n",
      "67. 48 with a score of 1.4436526167719466e-10\n",
      "68. 0 with a score of 1.4436526167719412e-10\n",
      "69. 9 with a score of 1.4436526167719298e-10\n",
      "70. 20 with a score of 1.4436526167719298e-10\n",
      "71. 5 with a score of 1.4436526167719257e-10\n",
      "72. 3 with a score of 1.4436526167719226e-10\n",
      "73. 41 with a score of 1.4436526167719205e-10\n",
      "74. 32 with a score of 1.4436526167719143e-10\n",
      "75. 42 with a score of 1.4436526167719143e-10\n",
      "76. 38 with a score of 1.443652616771911e-10\n",
      "77. 11 with a score of 1.4436526167719047e-10\n",
      "78. 15 with a score of 1.4436526167719026e-10\n",
      "79. 18 with a score of 1.4436526167718882e-10\n",
      "80. 91 with a score of 1.443652616771888e-10\n",
      "81. 84 with a score of 1.4436526167718786e-10\n",
      "82. 60 with a score of 1.4436526167718765e-10\n",
      "83. 63 with a score of 1.443652616771867e-10\n",
      "84. 95 with a score of 1.4436526167718662e-10\n",
      "85. 46 with a score of 1.4436526167718587e-10\n",
      "86. 53 with a score of 1.4436526167718504e-10\n",
      "87. 85 with a score of 1.4436526167718442e-10\n",
      "88. 92 with a score of 1.4436526167718305e-10\n",
      "89. 19 with a score of 1.4436526167718202e-10\n",
      "90. 79 with a score of 1.4436526167718088e-10\n",
      "91. 96 with a score of 1.4436526167718034e-10\n",
      "92. 77 with a score of 1.4436526167717835e-10\n",
      "93. 87 with a score of 1.4436526167717646e-10\n",
      "94. 98 with a score of 1.4436526167716726e-10\n",
      "95. 43 with a score of 1.4316779904705542e-10\n",
      "96. 26 with a score of 1.431677990470545e-10\n",
      "97. 54 with a score of 1.4308626395719949e-10\n",
      "98. 36 with a score of 1.4217184704078422e-10\n",
      "99. 7 with a score of 1.4110019916205924e-10\n",
      "100. 68 with a score of 1.4000091724822197e-10\n"
     ]
    }
   ],
   "source": [
    "import wrar\n",
    "\n",
    "rar = wrar.rar.RaR(data)\n",
    "rar.run(target, k=5, runs=50, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "rar_nocomp = wrar.rar.RaR(data)\n",
    "rar_nocomp.run(target, k=5, runs=50, split_iterations=10, compensate_imbalance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:52:14.912875Z",
     "start_time": "2017-07-19T01:49:49.769688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 850 1613 2435 2365  429  438  240  344 1164  122]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wRaR</th>\n",
       "      <th>RaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104472</td>\n",
       "      <td>0.102343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101216</td>\n",
       "      <td>0.111667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112994</td>\n",
       "      <td>0.110299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112253</td>\n",
       "      <td>0.119550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.111754</td>\n",
       "      <td>0.120270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.124282</td>\n",
       "      <td>0.117645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.122091</td>\n",
       "      <td>0.115224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.121818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126765</td>\n",
       "      <td>0.119238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.127611</td>\n",
       "      <td>0.118134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.133946</td>\n",
       "      <td>0.119822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.136332</td>\n",
       "      <td>0.122018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.121695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.137053</td>\n",
       "      <td>0.124578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.133580</td>\n",
       "      <td>0.123626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.125938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.137216</td>\n",
       "      <td>0.125012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.126057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.135576</td>\n",
       "      <td>0.122180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.132370</td>\n",
       "      <td>0.123910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.132163</td>\n",
       "      <td>0.123259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.134298</td>\n",
       "      <td>0.122945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.129542</td>\n",
       "      <td>0.122593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.129173</td>\n",
       "      <td>0.122879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.131048</td>\n",
       "      <td>0.123620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.122998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.131859</td>\n",
       "      <td>0.125326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.132051</td>\n",
       "      <td>0.123255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.132582</td>\n",
       "      <td>0.124343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.133714</td>\n",
       "      <td>0.125956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.133649</td>\n",
       "      <td>0.126527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.123034</td>\n",
       "      <td>0.123737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.123446</td>\n",
       "      <td>0.123221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.124032</td>\n",
       "      <td>0.119332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.120953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.123460</td>\n",
       "      <td>0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.123852</td>\n",
       "      <td>0.118672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.123080</td>\n",
       "      <td>0.120534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.121921</td>\n",
       "      <td>0.119019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.122057</td>\n",
       "      <td>0.124792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.122093</td>\n",
       "      <td>0.123371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.120659</td>\n",
       "      <td>0.123863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.127903</td>\n",
       "      <td>0.123873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.119337</td>\n",
       "      <td>0.123476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.127830</td>\n",
       "      <td>0.123168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.127373</td>\n",
       "      <td>0.122769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.128141</td>\n",
       "      <td>0.123247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.129423</td>\n",
       "      <td>0.125040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.129913</td>\n",
       "      <td>0.126169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wRaR       RaR\n",
       "1   0.104472  0.102343\n",
       "2   0.101216  0.111667\n",
       "3   0.112994  0.110299\n",
       "4   0.112253  0.119550\n",
       "5   0.111754  0.120270\n",
       "6   0.124282  0.117645\n",
       "7   0.122069  0.113099\n",
       "8   0.122091  0.115224\n",
       "9   0.121190  0.121818\n",
       "10  0.126765  0.119238\n",
       "11  0.127611  0.118134\n",
       "12  0.133946  0.119822\n",
       "13  0.136332  0.122018\n",
       "14  0.138445  0.121695\n",
       "15  0.137053  0.124578\n",
       "16  0.133580  0.123626\n",
       "17  0.136219  0.125938\n",
       "18  0.137216  0.125012\n",
       "19  0.135411  0.126057\n",
       "20  0.135576  0.122180\n",
       "21  0.132370  0.123910\n",
       "22  0.132163  0.123259\n",
       "23  0.134298  0.122945\n",
       "24  0.129542  0.122593\n",
       "25  0.129173  0.122879\n",
       "26  0.131048  0.123620\n",
       "27  0.132868  0.122998\n",
       "28  0.131859  0.125326\n",
       "29  0.132051  0.123255\n",
       "30  0.132582  0.124343\n",
       "31  0.133714  0.125956\n",
       "32  0.133649  0.126527\n",
       "33  0.123034  0.123737\n",
       "34  0.123446  0.123221\n",
       "35  0.124032  0.119332\n",
       "36  0.125289  0.120953\n",
       "37  0.123460  0.122032\n",
       "38  0.123852  0.118672\n",
       "39  0.123080  0.120534\n",
       "40  0.121921  0.119019\n",
       "41  0.122057  0.124792\n",
       "42  0.122093  0.123371\n",
       "43  0.120659  0.123863\n",
       "44  0.127903  0.123873\n",
       "45  0.119337  0.123476\n",
       "46  0.127830  0.123168\n",
       "47  0.127373  0.122769\n",
       "48  0.128141  0.123247\n",
       "49  0.129423  0.125040\n",
       "50  0.129913  0.126169"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Train/Test split\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# nm = RandomOverSampler(random_state=45622)\n",
    "# X_res, y_res = nm.fit_sample(X, y)\n",
    "\n",
    "# X = pd.DataFrame(X_res, columns=X.columns)\n",
    "# y = y_res\n",
    "\n",
    "print(np.unique(y, return_counts=True)[1])\n",
    "\n",
    "max_k = 50\n",
    "scores = pd.DataFrame(columns=['wRaR', 'RaR'], index=np.arange(1, max_k + 1)).fillna(0)\n",
    "\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for k in range(1, max_k + 1):\n",
    "    # clf = LinearSVC(class_weight='balanced')\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    # clf = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf, X[rank_columns_nocomp[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'RaR'] = np.mean(f1_macros)\n",
    "\n",
    "    # clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    # y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    # score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "    # scores.loc[k, 'RaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'RaR' + str(i)] += s\n",
    "\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for k in range(1, max_k + 1):\n",
    "    # clf_selected = LinearSVC(class_weight='balanced')\n",
    "    clf_selected = KNeighborsClassifier(n_neighbors=1)\n",
    "    # clf_selected = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf_selected, X[rank_columns[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'wRaR'] = np.mean(f1_macros)\n",
    "    \n",
    "    # clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    # y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    # score = f1_score(y_test, y_predict, average='macro')\n",
    "    # scores.loc[k, 'wRaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores.to_csv('final2_wRaR_10wrar_1nn_3cv.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:53:47.767428Z",
     "start_time": "2017-07-19T01:53:47.593148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEdCAYAAAD0NOuvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1d89bc470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['RaR'][:30], label='RaR')\n",
    "plt.plot(scores['wRaR'][:30], label='wRaR')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Number of features')\n",
    "ax.set_ylabel(r'Macro-averaged $F_1$ score')\n",
    "ax.set_ylim(0.0)\n",
    "ax.set_xlim(1)\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('final2_wRaR_10wrar_1nn_3cv_best30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T15:41:13.116482Z",
     "start_time": "2017-07-18T15:41:13.087250Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:12.076949Z",
     "start_time": "2017-07-11T15:32:12.060685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificially imbalance dataset\n",
    "class0 = data.loc[data[target] == 0]\n",
    "class1 = data.loc[data[target] == 1]\n",
    "imb_data = pd.concat([class1.sample(frac=0.02), class0]).reset_index(drop=True)\n",
    "# For perfectly balanced dataset, this will result in a 97.56:2.44 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:16.786006Z",
     "start_time": "2017-07-11T15:32:16.763970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test7.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=input_features, index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:01:27.039704Z",
     "start_time": "2017-07-11T16:01:26.981699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test8.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:38:33.508359Z",
     "start_time": "2017-07-11T16:38:33.485332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test9.arff\n",
    "weights = [0.7168886878437233, 0.1650913157879492, 0.7017219042598103, 0.5371651431980248,\n",
    "           0.4012494719087343, 0.08997742462568355, 0.4133240085774441, 0.3003377473503873,\n",
    "           0.12858013417222078, 0.5857996257919974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:52:39.059210Z",
     "start_time": "2017-07-12T08:52:39.029763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test10.arff\n",
    "weights = [0.2673055187472877, 0.196159223714542, 0.701161636883324, 0.765385125610722,\n",
    "           0.0011260947105074194, 0.22801651296579062, 0.8949526553930152, 0.13072480437597472,\n",
    "           0.6333889311003507, 0.7420344156127076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:70], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:53:11.655906Z",
     "start_time": "2017-07-12T08:53:11.653267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking = ground_truth.sort_values(0, axis=1, ascending=False).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:45:20.511140Z",
     "start_time": "2017-07-12T08:45:20.508965Z"
    }
   },
   "source": [
    "## Compensating HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standard HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:01:07.693901Z",
     "start_time": "2017-07-12T10:01:07.687405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "X_res = pd.DataFrame(X_res, columns=X_train.columns)\n",
    "# y_res = pd.DataFrame(y_res, columns=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T21:47:33.361286Z",
     "start_time": "2017-07-12T21:47:33.357061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts/len(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T20:04:24.776619Z",
     "start_time": "2017-07-14T20:04:24.455906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "values, counts = np.unique(datas[0][target], return_counts=True)\n",
    "marg = ax.bar(np.arange(5), counts/len(datas[0]), 0.35, color='green')\n",
    "cond = ax.bar(np.arange(5) + 0.35, [0.03, 0.05, 0.7, 0.07, 0.15], 0.35, color='orange')\n",
    "# ax.bar(np.arange(5), counts/len(data), 0.35, color='green')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Marginal and conditional probabilities')\n",
    "ax.set_xticks(np.arange(5) + 0.35 / 2)\n",
    "ax.set_xticklabels(('$c_1$', '$c_2$', '$c_3$', '$c_4$', '$c_5$'))\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax.legend((marg, cond), ('Marginal distribution', 'Conditional distribution'))\n",
    "plt.savefig('marg_cond')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:01:25.817496Z",
     "start_time": "2017-07-18T18:01:25.811517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T11:18:37.320520Z",
     "start_time": "2017-07-18T11:18:37.305589Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T13:18:49.993385Z",
     "start_time": "2017-07-17T13:18:49.971165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in datas:\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    print(counts/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:19:41.849443Z",
     "start_time": "2017-07-17T21:19:41.840916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T18:18:46.261757Z",
     "start_time": "2017-07-12T18:18:42.143869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "results_nocomp = []\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for j in range(25):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    results_nocomp.append(f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "results = []\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for j in range(25):\n",
    "    clf_selected = RandomForestClassifier()\n",
    "    clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "\n",
    "print('Dataset 1_whics_' + str(i+1))#, file=log)\n",
    "print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)))#, file=log)\n",
    "print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)))#, file=log)\n",
    "print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)))#, file=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:42.590702Z",
     "start_time": "2017-07-12T10:18:42.425386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_CG = [ground_truth.loc[0, ideal_ranking[:i].values].sum()\n",
    "            for i in range(len(ideal_ranking))]\n",
    "CG = [ground_truth.loc[0, [r for r in rank_columns[:i]]].sum()\n",
    "      for i in range(len(rank_columns))]\n",
    "nocomp_CG = [ground_truth.loc[0, [r for r in rank_columns_nocomp[:i]]].sum()\n",
    "             for i in range(len(rank_columns_nocomp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:43.542142Z",
     "start_time": "2017-07-12T10:18:43.425054Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(CG, label='Cumulative Gain Compensating HiCS')\n",
    "plt.plot(nocomp_CG, label='Cumulative Gain Standard HiCS')\n",
    "plt.plot(ideal_CG, label='Ideal gain')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.savefig('HiCS_test7_comp_imb2_CG_weightmod1-8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:32.297493Z",
     "start_time": "2017-07-12T10:20:32.287261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns_nocomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:30.514372Z",
     "start_time": "2017-07-12T10:20:30.504454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:50:21.019698Z",
     "start_time": "2017-07-11T16:50:20.946172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T00:28:02.788684Z",
     "start_time": "2017-07-14T00:13:20.765977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = open('binary_wHiCS_log.txt', 'w')\n",
    "for i, data in enumerate(datas):\n",
    "    # Compensating HiCS\n",
    "    #\n",
    "    #\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    cost_matrix = pd.DataFrame(columns=values)\n",
    "    for value, count in zip(values, counts):\n",
    "        weighting = (len(data) / count)\n",
    "        cost_matrix[value] = [weighting]\n",
    "    cost_matrix = cost_matrix\n",
    "    cost_matrix\n",
    "\n",
    "    from hics.result_storage import DefaultResultStorage\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage = DefaultResultStorage(input_features)\n",
    "\n",
    "    from hics.incremental_correlation import IncrementalCorrelation\n",
    "    correlation = IncrementalCorrelation(data, target, storage,\n",
    "                                         iterations=50, alpha=0.1,\n",
    "                                         drop_discrete=False, cost_matrix=cost_matrix)\n",
    "\n",
    "    correlation.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking = storage.get_relevancies().relevancy.sort_values(ascending=False)\n",
    "    rank_columns = [tup[0] for tup in ranking.index.values]\n",
    "\n",
    "    # Standard HiCS\n",
    "    #\n",
    "    #\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage_nocomp = DefaultResultStorage(input_features)\n",
    "    correlation_nocomp = IncrementalCorrelation(data, target, storage_nocomp,\n",
    "                                                iterations=50, alpha=0.1,\n",
    "                                                drop_discrete=False, cost_matrix=None)\n",
    "\n",
    "    correlation_nocomp.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking_nocomp = storage_nocomp.get_relevancies(\n",
    "    ).relevancy.sort_values(ascending=False)\n",
    "    rank_columns_nocomp = [tup[0] for tup in ranking_nocomp.index.values]\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    k = 10\n",
    "    results_nocomp = []\n",
    "    from sklearn.metrics import f1_score\n",
    "    for j in range(100):\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        results_nocomp.append(\n",
    "            f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "    results = []\n",
    "    for j in range(100):\n",
    "        clf_selected = RandomForestClassifier()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "    \n",
    "    print('Dataset 1_whics_' + str(i+1), file=log)\n",
    "    print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)), file=log)\n",
    "    print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)), file=log)\n",
    "    print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)), file=log)\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "max_k = 50\n",
    "classes = np.arange(len(np.unique(datas[0][target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=columns, index=np.arange(1,max_k+1)).fillna(0)\n",
    "\n",
    "for data in datas:\n",
    "    # Compensating RaR\n",
    "    #\n",
    "    #\n",
    "    rar = wrar.rar.RaR(data)\n",
    "    rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Standard RaR\n",
    "    #\n",
    "    #\n",
    "    rar_nocomp = wrar.rar.RaR(data)\n",
    "    rar_nocomp.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=False)\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "    from sklearn.metrics import f1_score\n",
    "    for k in range(1, max_k+1):\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "        scores.loc[k, 'RaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'RaR' + str(i)] += s\n",
    "        \n",
    "    rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "    for k in range(1, max_k+1):\n",
    "        clf_selected = GaussianNB()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        score = f1_score(y_test, y_predict, average='macro')\n",
    "        scores.loc[k, 'wRaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores /= len(datas)\n",
    "scores.to_csv('final_wRaR_3wrar_nb.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T23:14:52.548506Z",
     "start_time": "2017-07-18T23:14:52.542779Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        array -= np.amin(array)\n",
    "    array += 0.0000001\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
