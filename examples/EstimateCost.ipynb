{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T09:36:43.933071Z",
     "start_time": "2017-07-06T09:36:43.558349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csrar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:17.764349Z",
     "start_time": "2017-06-27T21:44:17.750035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/page-blocks0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:41:51.431380Z",
     "start_time": "2017-06-27T21:41:51.414851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For rootkit_imap...\n",
    "for cat_col in ['Atr-1', 'Atr-2', 'Atr-3']:\n",
    "    data[cat_col] = pd.Categorical(data[cat_col])\n",
    "    data[cat_col] = data[cat_col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:20.970181Z",
     "start_time": "2017-06-27T21:44:20.966531Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For page-block0.csv, convert 'positive'/'negative' to 0 and 1\n",
    "data['Class'] = pd.Categorical(data['Class'])\n",
    "data['Class'] = data['Class'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:40.104596Z",
     "start_time": "2017-06-27T21:44:40.093703Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:36:15.832456Z",
     "start_time": "2017-06-27T21:36:15.828502Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniques = np.unique(data['Class'], return_counts=True)\n",
    "perc = list(map(lambda c: c/len(data), uniques[1]))\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T09:37:24.739398Z",
     "start_time": "2017-07-06T09:36:47.069179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/test5.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T09:37:24.761057Z",
     "start_time": "2017-07-06T09:37:24.740621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[150] = data[150].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T09:37:24.967229Z",
     "start_time": "2017-07-06T09:37:24.762216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificially imbalance dataset\n",
    "class0 = data.loc[data[150] == 0]\n",
    "class1 = data.loc[data[150] == 1]\n",
    "imb_data = pd.concat([class1.sample(frac=0.1), class0]).reset_index(drop=True)\n",
    "# For perfectly balanced dataset, this will result in a 97.56:2.44 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T12:09:37.180775Z",
     "start_time": "2017-06-30T12:09:37.174835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T09:37:28.143280Z",
     "start_time": "2017-07-06T09:37:27.996327Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 150\n",
    "X = imb_data.drop(target, axis=1)\n",
    "y = imb_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T16:01:44.037Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = 0\n",
    "for i in range(5):\n",
    "    rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "    # RaR uses columns with string label only\n",
    "    rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    target = str(target)\n",
    "    rar = csrar.rar.RaR(rar_data)\n",
    "    rar.run(target, k=5, runs=100, split_iterations=10, compensate_imbalance=False)\n",
    "    \n",
    "    # Evaluate, average relative error rates\n",
    "    score = pd.DataFrame(columns=['Class 0', 'Class 1'], index=np.arange(max_k))\n",
    "    score = score.fillna(0)\n",
    "    for i in range(1, max_k):\n",
    "        errors = eval_rar_ranking(rar.feature_ranking, int(target), k=i)\n",
    "        score.loc[i, 'Class 0'] = errors[0.0][0]\n",
    "        score.loc[i, 'Class 1'] = errors[1.0][0]\n",
    "        \n",
    "    scores += score\n",
    "scores /= 5\n",
    "scores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['Class 0'], label='Class 0')\n",
    "plt.plot(scores['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_avg_nocomp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T16:01:45.149Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_comp = 0\n",
    "max_k = 150\n",
    "\n",
    "for i in range(5):\n",
    "    rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "    # RaR uses columns with string label only\n",
    "    rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    target = str(target)\n",
    "    rar_compensate = csrar.rar.RaR(rar_data)\n",
    "    rar_compensate.run(target, k=5, runs=100, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Evaluate, average relative error rates\n",
    "    score = pd.DataFrame(columns=['Class 0', 'Class 1'], index=np.arange(max_k))\n",
    "    score = score.fillna(0)\n",
    "    for i in range(1, max_k):\n",
    "        errors = eval_rar_ranking(rar_compensate.feature_ranking, int(target), k=i)\n",
    "        score.loc[i, 'Class 0'] = errors[0.0][0]\n",
    "        score.loc[i, 'Class 1'] = errors[1.0][0]\n",
    "        \n",
    "    scores_comp += score\n",
    "scores_comp /= 5\n",
    "scores_compo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores_comp['Class 0'], label='Class 0')\n",
    "plt.plot(scores_comp['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_avg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T14:59:20.577Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-06T10:12:44.160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated cost matrix:\n",
      "        0.0        1.0\n",
      "0  1.098629  11.139018\n",
      "Overall cost matrix:\n",
      "        0.0        1.0\n",
      "0  1.098629  11.139018\n",
      "Relevance: 63.00%     "
     ]
    }
   ],
   "source": [
    "scores_comp = pd.DataFrame(columns=['Class 0', 'Class 1'], index=np.arange(1, 8)).fillna(0)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "    # RaR uses columns with string label only\n",
    "    rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    target = str(target)\n",
    "    rar_compensate = csrar.rar.RaR(rar_data)\n",
    "    rar_compensate.run(target, k=5, runs=100, split_iterations=10, compensate_imbalance=True, weight_mod=i)\n",
    "\n",
    "    # Evaluate, average relative error rates\n",
    "    errors = eval_rar_ranking(rar_compensate.feature_ranking, int(target), k=10)\n",
    "    scores_comp.loc[i, 'Class 0'] = errors[0.0][0]\n",
    "    scores_comp.loc[i, 'Class 1'] = errors[1.0][0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores_comp['Class 0'], label='Class 0')\n",
    "plt.plot(scores_comp['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0, 1])\n",
    "axes.set_ylabel('Relative error rate')\n",
    "axes.set_xlabel('Weighting exponent')\n",
    "plt.savefig('weight_higher')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:55:15.998436Z",
     "start_time": "2017-07-04T14:55:15.989149Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T14:59:25.096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['Class 0'], label='Class 0')\n",
    "plt.plot(scores['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_nocomp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:47:30.116483Z",
     "start_time": "2017-06-27T21:47:29.888089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_frame2 = eval_rar_ranking(rar_compensate.feature_ranking, k=4)\n",
    "error_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:07:47.409552Z",
     "start_time": "2017-06-27T16:07:47.407584Z"
    }
   },
   "source": [
    "### With selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-06T10:09:36.508403Z",
     "start_time": "2017-07-06T10:09:36.486834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_rar_ranking(ranking, target, k=3):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    \n",
    "    clf_selected = ExtraTreesClassifier(n_jobs=-1)\n",
    "    selected_features = list(map(lambda f: int(f[0]), ranking[:k]))\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    \n",
    "    # Rebalance\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_sample(X_train_s, y_train)\n",
    "    \n",
    "    clf_selected.fit(X_res, y_res)\n",
    "    y_predict = clf_selected.predict(X_test_s)\n",
    "    error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[target])])\n",
    "    for real, predicted in zip(y_test, y_predict):\n",
    "        if real != predicted:\n",
    "            error_rates[real]['errors'] += 1\n",
    "        error_rates[real]['sum'] += 1\n",
    "\n",
    "    error_frame = pd.DataFrame(index=[0], columns=np.unique(data[target]))\n",
    "    for value, rates in error_rates.items():\n",
    "        error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "    return error_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:06:29.802362Z",
     "start_time": "2017-06-27T16:06:29.798890Z"
    }
   },
   "source": [
    "### Without selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:12:39.228396Z",
     "start_time": "2017-07-04T14:12:33.466558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resampling for imbalanced learn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:12:40.407229Z",
     "start_time": "2017-07-04T14:12:39.229327Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_jobs=-1)\n",
    "clf.fit(X_res, y_res)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[150])])\n",
    "for real, predicted in zip(y_test, y_predict):\n",
    "    if real != predicted:\n",
    "        error_rates[real]['errors'] += 1\n",
    "    error_rates[real]['sum'] += 1\n",
    "error_frame = pd.DataFrame(index=[0], columns=np.unique(data[150]))\n",
    "for value, rates in error_rates.items():\n",
    "    error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "error_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:09:02.712088Z",
     "start_time": "2017-06-30T14:09:02.601069Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda p: p == 1.0, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:09:11.391744Z",
     "start_time": "2017-06-30T14:09:11.388894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:41:19.951462Z",
     "start_time": "2017-06-27T16:41:19.842950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier for Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:07:28.720313Z",
     "start_time": "2017-06-30T14:07:11.342466Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:07:28.770962Z",
     "start_time": "2017-06-30T14:07:28.721222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pdb 1\n",
    "y_predict = clf.predict(X_test)\n",
    "error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[150])])\n",
    "for real, predicted in zip(y_test, y_predict):\n",
    "    if real != predicted:\n",
    "        error_rates[real]['errors'] += 1\n",
    "    error_rates[real]['sum'] += 1\n",
    "error_frame = pd.DataFrame(index=[0], columns=np.unique(data[150]))\n",
    "for value, rates in error_rates.items():\n",
    "    error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "error_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:21.148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking = []\n",
    "for index, importance in enumerate(clf.feature_importances_):\n",
    "    ranking.append((data.columns[index], importance))\n",
    "ranking.sort(key=lambda r: r[1], reverse=True)\n",
    "for (index, rank) in enumerate(ranking):\n",
    "        print('{}. {} with a score of {}'.format(index + 1, rank[0], rank[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with top k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:24.460Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "scores = pd.DataFrame(columns=['RaR', 'DecisionTree'], index=np.arange(40))\n",
    "scores = scores.fillna(0)\n",
    "max_k = 40\n",
    "\n",
    "# RaR\n",
    "for i in range(1,max_k):\n",
    "    clf_selected = ExtraTreesClassifier(max_features=i, n_jobs=-1)\n",
    "    selected_features = list(map(lambda f: int(f[0]), rar.feature_ranking[:i]))\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s, y_train)\n",
    "    scores.loc[i, 'RaR'] = clf_selected.score(X_test_s, y_test)\n",
    "    sys.stdout.write('\\rBenchmark: {}%     '.format(100 * i / (2*max_k)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# DecisionTree\n",
    "for i in range(1,max_k):\n",
    "    clf_selected = ExtraTreesClassifier(max_features=i, n_jobs=-1)\n",
    "    selected_features = [r[0] for r in ranking[:i]]\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s, y_train)\n",
    "    scores.loc[i, 'DecisionTree'] = clf_selected.score(X_test_s, y_test)\n",
    "    sys.stdout.write('\\rBenchmark: {}%     '.format(50 + 100 * i / (2*max_k)))\n",
    "    sys.stdout.flush()\n",
    "print('Benchmark: 100.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:27.588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['DecisionTree'], label='DecisionTree')\n",
    "plt.plot(scores['RaR'], label='RaR')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('test4_FS_ExtraTrees_Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case we need to look at the tree\n",
    "from sklearn import tree\n",
    "import pydot\n",
    "from sklearn.externals.six import StringIO\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About test2.arff:\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(24860, 25140)  \n",
    "seed=0\n",
    "#### About test3.arff\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(249786, 250214)  \n",
    "#### About test4.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29)  \n",
    "dependent=Vector(100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149)  \n",
    "duplicated=Vector((7,168), (10,157), (24,159), (28,162), (30,166), (50,169), (61,154), (82,158), (99,167), (104,156), (107,151), (113,164), (117,155), (117,165), (124,150), (135,160), (139,152), (145,161), (146,153), (147,163))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), (10, 11, 12, 13, 14), (15, 16, 17)]  \n",
    "distribution=List(250085, 249915)  \n",
    "#### About test5.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)  \n",
    "dependent=Vector(80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109)  \n",
    "duplicated=Vector((4,118), (8,114), (8,146), (9,137), (9,144), (10,131), (17,123), (22,116), (24,120), (24,142), (25,125), (35,127), (42,119), (43,122), (45,111), (48,134), (50,132), (52,110), (54,138), (57,112), (57,115), (57,149), (62,141), (64,136), (70,117), (70,148), (73,126), (76,133), (77,140), (78,143), (83,113), (84,139), (91,145), (92,121), (93,128), (93,135), (95,124), (103,129), (104,130), (105,147))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4), (5, 6, 7, 8, 9, 10, 11, 12, 13, 14)]  \n",
    "distribution=List(99718, 100282)  \n",
    "\n",
    "#### About test7.arff\n",
    "useful=[0,1,2,3,4,5,6,7,8,9]  \n",
    "weights=[0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171, 0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121, 0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
