{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T12:37:29.560533Z",
     "start_time": "2017-07-04T12:37:29.556994Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csrar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:17.764349Z",
     "start_time": "2017-06-27T21:44:17.750035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/page-blocks0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:41:51.431380Z",
     "start_time": "2017-06-27T21:41:51.414851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For rootkit_imap...\n",
    "for cat_col in ['Atr-1', 'Atr-2', 'Atr-3']:\n",
    "    data[cat_col] = pd.Categorical(data[cat_col])\n",
    "    data[cat_col] = data[cat_col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:20.970181Z",
     "start_time": "2017-06-27T21:44:20.966531Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For page-block0.csv, convert 'positive'/'negative' to 0 and 1\n",
    "data['Class'] = pd.Categorical(data['Class'])\n",
    "data['Class'] = data['Class'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:44:40.104596Z",
     "start_time": "2017-06-27T21:44:40.093703Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:36:15.832456Z",
     "start_time": "2017-06-27T21:36:15.828502Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniques = np.unique(data['Class'], return_counts=True)\n",
    "perc = list(map(lambda c: c/len(data), uniques[1]))\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T12:38:14.109125Z",
     "start_time": "2017-07-04T12:37:36.070846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/test5.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T12:38:14.133554Z",
     "start_time": "2017-07-04T12:38:14.110448Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[150] = data[150].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T13:40:11.356487Z",
     "start_time": "2017-07-04T13:40:11.186015Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificially imbalance dataset\n",
    "class0 = data.loc[data[150] == 0]\n",
    "class1 = data.loc[data[150] == 1]\n",
    "imb_data = pd.concat([class1.sample(frac=0.1), class0]).reset_index(drop=True)\n",
    "# For perfectly balanced dataset, this will result in a 97.56:2.44 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T12:09:37.180775Z",
     "start_time": "2017-06-30T12:09:37.174835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About test2.arff:\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(24860, 25140)  \n",
    "seed=0\n",
    "#### About test3.arff\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(249786, 250214)  \n",
    "#### About test4.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29)  \n",
    "dependent=Vector(100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149)  \n",
    "duplicated=Vector((7,168), (10,157), (24,159), (28,162), (30,166), (50,169), (61,154), (82,158), (99,167), (104,156), (107,151), (113,164), (117,155), (117,165), (124,150), (135,160), (139,152), (145,161), (146,153), (147,163))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), (10, 11, 12, 13, 14), (15, 16, 17)]  \n",
    "distribution=List(250085, 249915)  \n",
    "#### About test5.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)  \n",
    "dependent=Vector(80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109)  \n",
    "duplicated=Vector((4,118), (8,114), (8,146), (9,137), (9,144), (10,131), (17,123), (22,116), (24,120), (24,142), (25,125), (35,127), (42,119), (43,122), (45,111), (48,134), (50,132), (52,110), (54,138), (57,112), (57,115), (57,149), (62,141), (64,136), (70,117), (70,148), (73,126), (76,133), (77,140), (78,143), (83,113), (84,139), (91,145), (92,121), (93,128), (93,135), (95,124), (103,129), (104,130), (105,147))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4), (5, 6, 7, 8, 9, 10, 11, 12, 13, 14)]  \n",
    "distribution=List(99718, 100282)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T13:40:14.706396Z",
     "start_time": "2017-07-04T13:40:14.582343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 150\n",
    "X = imb_data.drop(target, axis=1)\n",
    "y = imb_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T16:01:44.037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "Redundancy: 100.00%    \n",
      "1. 114 with a score of 1.0\n",
      "2. 6 with a score of 0.993495711425336\n",
      "3. 8 with a score of 0.9276812791206879\n",
      "4. 7 with a score of 0.8438356714350667\n",
      "5. 77 with a score of 0.8171778049859214\n",
      "6. 1 with a score of 0.5542110174410589\n",
      "7. 124 with a score of 0.5201126673045839\n",
      "8. 128 with a score of 0.5004327373293125\n",
      "9. 106 with a score of 0.4663128733021168\n",
      "10. 101 with a score of 0.4618412839594955\n",
      "11. 99 with a score of 0.4528488772482379\n",
      "12. 113 with a score of 0.377112231170001\n",
      "13. 4 with a score of 0.3529905158770467\n",
      "14. 104 with a score of 0.33656155983989294\n",
      "15. 5 with a score of 0.33137679845009643\n",
      "16. 82 with a score of 0.3288339251380033\n",
      "17. 109 with a score of 0.31330887930506296\n",
      "18. 59 with a score of 0.2901307509919748\n",
      "19. 98 with a score of 0.27901600631509793\n",
      "20. 14 with a score of 0.2721116942941003\n",
      "21. 51 with a score of 0.2701465257675051\n",
      "22. 57 with a score of 0.2535549910142867\n",
      "23. 142 with a score of 0.25175440415514255\n",
      "24. 2 with a score of 0.2510455031858083\n",
      "25. 107 with a score of 0.24911910776262802\n",
      "26. 126 with a score of 0.2361980050011152\n",
      "27. 37 with a score of 0.23606233894757367\n",
      "28. 105 with a score of 0.23606233894757359\n",
      "29. 132 with a score of 0.2066493985795448\n",
      "30. 148 with a score of 0.1889198944907524\n",
      "31. 45 with a score of 0.18686634848242722\n",
      "32. 58 with a score of 0.18376933210315935\n",
      "33. 67 with a score of 0.17867575805117797\n",
      "34. 50 with a score of 0.1773257752727819\n",
      "35. 134 with a score of 0.17512588839177146\n",
      "36. 116 with a score of 0.17426021047608908\n",
      "37. 115 with a score of 0.17249798690410467\n",
      "38. 75 with a score of 0.1677920291555397\n",
      "39. 22 with a score of 0.15897779191344427\n",
      "40. 147 with a score of 0.15897779152620803\n",
      "41. 71 with a score of 0.15545156722513673\n",
      "42. 136 with a score of 0.15262416264462658\n",
      "43. 119 with a score of 0.14879537656224912\n",
      "44. 89 with a score of 0.14879512739492937\n",
      "45. 95 with a score of 0.1487951249754885\n",
      "46. 121 with a score of 0.14666792848273993\n",
      "47. 62 with a score of 0.1323037078333835\n",
      "48. 88 with a score of 0.13230370783338305\n",
      "49. 131 with a score of 0.1295771255215475\n",
      "50. 52 with a score of 0.12715281772396736\n",
      "51. 17 with a score of 0.12594690566681904\n",
      "52. 117 with a score of 0.12594690566681857\n",
      "53. 56 with a score of 0.10280021446510855\n",
      "54. 90 with a score of 0.09238359460968014\n",
      "55. 55 with a score of 0.09238359283235106\n",
      "56. 30 with a score of 0.0867601010970354\n",
      "57. 33 with a score of 0.08361394184830492\n",
      "58. 130 with a score of 0.08361393328983602\n",
      "59. 40 with a score of 0.07763780445259068\n",
      "60. 25 with a score of 0.06828059858046132\n",
      "61. 120 with a score of 0.06759488046629829\n",
      "62. 63 with a score of 0.05298657256490544\n",
      "63. 36 with a score of 0.04814180440648127\n",
      "64. 145 with a score of 0.04814180440648127\n",
      "65. 70 with a score of 0.04636410105854606\n",
      "66. 49 with a score of 0.045563633467364695\n",
      "67. 3 with a score of 0.04556363154046453\n",
      "68. 61 with a score of 0.04556363154046453\n",
      "69. 26 with a score of 0.04529508269495208\n",
      "70. 97 with a score of 0.045292168693684416\n",
      "71. 39 with a score of 0.04529216600961445\n",
      "72. 18 with a score of 0.04463443239015346\n",
      "73. 42 with a score of 0.03577265752541576\n",
      "74. 34 with a score of 0.03577265684390137\n",
      "75. 66 with a score of 0.03577265684390137\n",
      "76. 79 with a score of 0.019102756144308786\n",
      "77. 138 with a score of 0.019102629714038515\n",
      "78. 122 with a score of 0.01687632658262047\n",
      "79. 35 with a score of 0.006831154603005655\n",
      "80. 94 with a score of 0.006831154603005655\n",
      "81. 60 with a score of 0.004233117257633942\n",
      "82. 31 with a score of 4.7906195102579e-09\n",
      "83. 32 with a score of 2.2759127298861512e-09\n",
      "84. 44 with a score of 6.611447499682485e-10\n",
      "85. 125 with a score of 5.753372055963865e-10\n",
      "86. 84 with a score of 4.895033623573388e-10\n",
      "87. 11 with a score of 4.88655801494333e-10\n",
      "88. 41 with a score of 3.2391957441813233e-10\n",
      "89. 110 with a score of 2.797135074762953e-10\n",
      "90. 111 with a score of 2.797135074762953e-10\n",
      "91. 47 with a score of 2.47596114828012e-10\n",
      "92. 80 with a score of 2.4247983566204053e-10\n",
      "93. 143 with a score of 2.4118742539008217e-10\n",
      "94. 102 with a score of 2.351354603015245e-10\n",
      "95. 20 with a score of 2.2689616247717938e-10\n",
      "96. 68 with a score of 2.1945880976732054e-10\n",
      "97. 28 with a score of 2.183658983027309e-10\n",
      "98. 43 with a score of 2.1312445305875427e-10\n",
      "99. 48 with a score of 2.0467815237000422e-10\n",
      "100. 78 with a score of 2.0082859415795536e-10\n",
      "101. 38 with a score of 1.9478571521788562e-10\n",
      "102. 112 with a score of 1.9478571521788562e-10\n",
      "103. 0 with a score of 1.8996642845203634e-10\n",
      "104. 83 with a score of 1.7534646273996388e-10\n",
      "105. 9 with a score of 1.7532570580960912e-10\n",
      "106. 10 with a score of 1.7532570580960912e-10\n",
      "107. 12 with a score of 1.7532570580960912e-10\n",
      "108. 13 with a score of 1.7532570580960912e-10\n",
      "109. 16 with a score of 1.7532570580960912e-10\n",
      "110. 19 with a score of 1.7532570580960912e-10\n",
      "111. 21 with a score of 1.7532570580960912e-10\n",
      "112. 27 with a score of 1.7532570580960912e-10\n",
      "113. 46 with a score of 1.7532570580960912e-10\n",
      "114. 53 with a score of 1.7532570580960912e-10\n",
      "115. 65 with a score of 1.7532570580960912e-10\n",
      "116. 72 with a score of 1.7532570580960912e-10\n",
      "117. 73 with a score of 1.7532570580960912e-10\n",
      "118. 74 with a score of 1.7532570580960912e-10\n",
      "119. 81 with a score of 1.7532570580960912e-10\n",
      "120. 86 with a score of 1.7532570580960912e-10\n",
      "121. 87 with a score of 1.7532570580960912e-10\n",
      "122. 91 with a score of 1.7532570580960912e-10\n",
      "123. 93 with a score of 1.7532570580960912e-10\n",
      "124. 100 with a score of 1.7532570580960912e-10\n",
      "125. 118 with a score of 1.7532570580960912e-10\n",
      "126. 127 with a score of 1.7532570580960912e-10\n",
      "127. 137 with a score of 1.7532570580960912e-10\n",
      "128. 141 with a score of 1.7532570580960912e-10\n",
      "129. 144 with a score of 1.7532570580960912e-10\n",
      "130. 146 with a score of 1.7532570580960912e-10\n",
      "131. 149 with a score of 1.7532570580960912e-10\n",
      "132. 85 with a score of 1.7530335816081005e-10\n",
      "133. 135 with a score of 1.7530335816081005e-10\n",
      "134. 69 with a score of 1.7525343827720355e-10\n",
      "135. 15 with a score of 1.7523792399296116e-10\n",
      "136. 76 with a score of 1.7523792399296116e-10\n",
      "137. 64 with a score of 1.7523599965610628e-10\n",
      "138. 54 with a score of 1.7504333038724305e-10\n",
      "139. 96 with a score of 1.7487537415811258e-10\n",
      "140. 29 with a score of 1.744589902820767e-10\n",
      "141. 92 with a score of 1.740918049519638e-10\n",
      "142. 108 with a score of 1.6713112513265658e-10\n",
      "143. 133 with a score of 1.664400481669749e-10\n",
      "144. 140 with a score of 1.664400481669749e-10\n",
      "145. 23 with a score of 1.661124663246453e-10\n",
      "146. 24 with a score of 1.599027103320354e-10\n",
      "147. 139 with a score of 1.599027103320354e-10\n",
      "148. 129 with a score of 1.540754978747959e-10\n",
      "149. 103 with a score of 1.1829803647109417e-10\n",
      "150. 123 with a score of 1.1818245528845877e-10\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "Redundancy: 46.00%     "
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(5):\n",
    "    rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "    # RaR uses columns with string label only\n",
    "    rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    target = str(target)\n",
    "    rar = csrar.rar.RaR(rar_data)\n",
    "    rar.run(target, k=5, runs=100, split_iterations=10, compensate_imbalance=False)\n",
    "    \n",
    "    # Evaluate, average relative error rates\n",
    "    score = pd.DataFrame(columns=['Class 0', 'Class 1'], index=np.arange(max_k))\n",
    "    score = score.fillna(0)\n",
    "    for i in range(1, max_k):\n",
    "        errors = eval_rar_ranking(rar.feature_ranking, int(target), k=i)\n",
    "        score.loc[i, 'Class 0'] = errors[0.0][0]\n",
    "        score.loc[i, 'Class 1'] = errors[1.0][0]\n",
    "        \n",
    "    scores += score\n",
    "scores /= 5\n",
    "scores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['Class 0'], label='Class 0')\n",
    "plt.plot(scores['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_avg_nocomp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T16:01:45.149Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_comp = 0\n",
    "max_k = 150\n",
    "\n",
    "for i in range(5):\n",
    "    rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "    # RaR uses columns with string label only\n",
    "    rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    target = str(target)\n",
    "    rar_compensate = csrar.rar.RaR(rar_data)\n",
    "    rar_compensate.run(target, k=5, runs=100, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Evaluate, average relative error rates\n",
    "    score = pd.DataFrame(columns=['Class 0', 'Class 1'], index=np.arange(max_k))\n",
    "    score = score.fillna(0)\n",
    "    for i in range(1, max_k):\n",
    "        errors = eval_rar_ranking(rar_compensate.feature_ranking, int(target), k=i)\n",
    "        score.loc[i, 'Class 0'] = errors[0.0][0]\n",
    "        score.loc[i, 'Class 1'] = errors[1.0][0]\n",
    "        \n",
    "    scores_comp += score\n",
    "scores_comp /= 5\n",
    "scores_comp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores_comp['Class 0'], label='Class 0')\n",
    "plt.plot(scores_comp['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_avg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T14:59:20.577Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:55:15.998436Z",
     "start_time": "2017-07-04T14:55:15.989149Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.376257</td>\n",
       "      <td>0.621330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240742</td>\n",
       "      <td>0.740164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178990</td>\n",
       "      <td>0.784502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.115722</td>\n",
       "      <td>0.856201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128811</td>\n",
       "      <td>0.691232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.135854</td>\n",
       "      <td>0.604554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.631716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.096808</td>\n",
       "      <td>0.493709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.098304</td>\n",
       "      <td>0.498902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.091022</td>\n",
       "      <td>0.519273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.098524</td>\n",
       "      <td>0.497304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.093236</td>\n",
       "      <td>0.522668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.090104</td>\n",
       "      <td>0.534452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.104769</td>\n",
       "      <td>0.492710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.099042</td>\n",
       "      <td>0.503695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.103931</td>\n",
       "      <td>0.497503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.484921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.099501</td>\n",
       "      <td>0.503096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.101796</td>\n",
       "      <td>0.504294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.098663</td>\n",
       "      <td>0.517476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.092737</td>\n",
       "      <td>0.522668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.538047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.089824</td>\n",
       "      <td>0.544438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.088907</td>\n",
       "      <td>0.546235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.093077</td>\n",
       "      <td>0.516477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.088029</td>\n",
       "      <td>0.538047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.086612</td>\n",
       "      <td>0.548632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.083520</td>\n",
       "      <td>0.555622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.091281</td>\n",
       "      <td>0.545037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.037470</td>\n",
       "      <td>0.691232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.037969</td>\n",
       "      <td>0.711005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.041121</td>\n",
       "      <td>0.690034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.038268</td>\n",
       "      <td>0.717795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.036512</td>\n",
       "      <td>0.678250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.038248</td>\n",
       "      <td>0.706211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.690234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.039385</td>\n",
       "      <td>0.699021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.038827</td>\n",
       "      <td>0.717795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.037530</td>\n",
       "      <td>0.728580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.040583</td>\n",
       "      <td>0.725984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.677651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.038188</td>\n",
       "      <td>0.737567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.039106</td>\n",
       "      <td>0.712003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.041081</td>\n",
       "      <td>0.716397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.039824</td>\n",
       "      <td>0.727981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.719792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.715598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.040463</td>\n",
       "      <td>0.728780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.731975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.718794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.037969</td>\n",
       "      <td>0.719193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.737168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.037789</td>\n",
       "      <td>0.736169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.037590</td>\n",
       "      <td>0.726183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.035435</td>\n",
       "      <td>0.727581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.035415</td>\n",
       "      <td>0.723986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.718794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.039765</td>\n",
       "      <td>0.740363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.036034</td>\n",
       "      <td>0.766327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class 0   Class 1\n",
       "0    0.000000  0.000000\n",
       "1    0.376257  0.621330\n",
       "2    0.240742  0.740164\n",
       "3    0.178990  0.784502\n",
       "4    0.115722  0.856201\n",
       "5    0.128811  0.691232\n",
       "6    0.135854  0.604554\n",
       "7    0.117917  0.631716\n",
       "8    0.096808  0.493709\n",
       "9    0.098304  0.498902\n",
       "10   0.091022  0.519273\n",
       "11   0.098524  0.497304\n",
       "12   0.093236  0.522668\n",
       "13   0.090104  0.534452\n",
       "14   0.104769  0.492710\n",
       "15   0.099042  0.503695\n",
       "16   0.103931  0.497503\n",
       "17   0.107143  0.484921\n",
       "18   0.099501  0.503096\n",
       "19   0.101796  0.504294\n",
       "20   0.098663  0.517476\n",
       "21   0.092737  0.522668\n",
       "22   0.090702  0.538047\n",
       "23   0.089824  0.544438\n",
       "24   0.088907  0.546235\n",
       "25   0.093077  0.516477\n",
       "26   0.088029  0.538047\n",
       "27   0.086612  0.548632\n",
       "28   0.083520  0.555622\n",
       "29   0.091281  0.545037\n",
       "..        ...       ...\n",
       "120  0.037470  0.691232\n",
       "121  0.037969  0.711005\n",
       "122  0.041121  0.690034\n",
       "123  0.038268  0.717795\n",
       "124  0.036512  0.678250\n",
       "125  0.038248  0.706211\n",
       "126  0.038966  0.690234\n",
       "127  0.039385  0.699021\n",
       "128  0.038827  0.717795\n",
       "129  0.037530  0.728580\n",
       "130  0.040583  0.725984\n",
       "131  0.041600  0.677651\n",
       "132  0.038188  0.737567\n",
       "133  0.039106  0.712003\n",
       "134  0.041081  0.716397\n",
       "135  0.039824  0.727981\n",
       "136  0.040762  0.719792\n",
       "137  0.037789  0.715598\n",
       "138  0.040463  0.728780\n",
       "139  0.039565  0.731975\n",
       "140  0.035694  0.718794\n",
       "141  0.037969  0.719193\n",
       "142  0.038867  0.737168\n",
       "143  0.037789  0.736169\n",
       "144  0.037590  0.726183\n",
       "145  0.035435  0.727581\n",
       "146  0.035415  0.723986\n",
       "147  0.037171  0.718794\n",
       "148  0.039765  0.740363\n",
       "149  0.036034  0.766327\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-04T14:59:25.096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['Class 0'], label='Class 0')\n",
    "plt.plot(scores['Class 1'], label='Class 1')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('RaR_test5_imb_nocomp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T21:47:30.116483Z",
     "start_time": "2017-06-27T21:47:29.888089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_frame2 = eval_rar_ranking(rar_compensate.feature_ranking, k=4)\n",
    "error_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:07:47.409552Z",
     "start_time": "2017-06-27T16:07:47.407584Z"
    }
   },
   "source": [
    "### With selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:33:59.447310Z",
     "start_time": "2017-07-04T14:33:59.382226Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_rar_ranking(ranking, target, k=3):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    \n",
    "    clf_selected = ExtraTreesClassifier(n_jobs=-1)\n",
    "    selected_features = list(map(lambda f: int(f[0]), ranking[:k]))\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    \n",
    "    # Rebalance\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_sample(X_train_s, y_train)\n",
    "    \n",
    "    clf_selected.fit(X_res, y_res)\n",
    "    y_predict = clf_selected.predict(X_test_s)\n",
    "    error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[target])])\n",
    "    for real, predicted in zip(y_test, y_predict):\n",
    "        if real != predicted:\n",
    "            error_rates[real]['errors'] += 1\n",
    "        error_rates[real]['sum'] += 1\n",
    "\n",
    "    error_frame = pd.DataFrame(index=[0], columns=np.unique(data[target]))\n",
    "    for value, rates in error_rates.items():\n",
    "        error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "    return error_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:06:29.802362Z",
     "start_time": "2017-06-27T16:06:29.798890Z"
    }
   },
   "source": [
    "### Without selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:12:39.228396Z",
     "start_time": "2017-07-04T14:12:33.466558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resampling for imbalanced learn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T14:12:40.407229Z",
     "start_time": "2017-07-04T14:12:39.229327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.740363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.0       1.0\n",
       "0  0.036991  0.740363"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_jobs=-1)\n",
    "clf.fit(X_res, y_res)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[150])])\n",
    "for real, predicted in zip(y_test, y_predict):\n",
    "    if real != predicted:\n",
    "        error_rates[real]['errors'] += 1\n",
    "    error_rates[real]['sum'] += 1\n",
    "error_frame = pd.DataFrame(index=[0], columns=np.unique(data[150]))\n",
    "for value, rates in error_rates.items():\n",
    "    error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "error_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:09:02.712088Z",
     "start_time": "2017-06-30T14:09:02.601069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(filter(lambda p: p == 1.0, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:09:11.391744Z",
     "start_time": "2017-06-30T14:09:11.388894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {'errors': 211, 'sum': 50141}, 1.0: {'errors': 1149, 'sum': 1247}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T16:41:19.951462Z",
     "start_time": "2017-06-27T16:41:19.842950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier for Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:07:28.720313Z",
     "start_time": "2017-06-30T14:07:11.342466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95971822215303182"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T14:07:28.770962Z",
     "start_time": "2017-06-30T14:07:28.721222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021998</td>\n",
       "      <td>0.775461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0.0       1.0\n",
       "0  0.021998  0.775461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb 1\n",
    "y_predict = clf.predict(X_test)\n",
    "error_rates = dict([(value, {'sum': 0, 'errors': 0}) for value in np.unique(data[150])])\n",
    "for real, predicted in zip(y_test, y_predict):\n",
    "    if real != predicted:\n",
    "        error_rates[real]['errors'] += 1\n",
    "    error_rates[real]['sum'] += 1\n",
    "error_frame = pd.DataFrame(index=[0], columns=np.unique(data[150]))\n",
    "for value, rates in error_rates.items():\n",
    "    error_frame[value] = [rates['errors'] / (rates['sum'])]\n",
    "error_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:21.148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking = []\n",
    "for index, importance in enumerate(clf.feature_importances_):\n",
    "    ranking.append((data.columns[index], importance))\n",
    "ranking.sort(key=lambda r: r[1], reverse=True)\n",
    "for (index, rank) in enumerate(ranking):\n",
    "        print('{}. {} with a score of {}'.format(index + 1, rank[0], rank[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with top k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:24.460Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "scores = pd.DataFrame(columns=['RaR', 'DecisionTree'], index=np.arange(40))\n",
    "scores = scores.fillna(0)\n",
    "max_k = 40\n",
    "\n",
    "# RaR\n",
    "for i in range(1,max_k):\n",
    "    clf_selected = ExtraTreesClassifier(max_features=i, n_jobs=-1)\n",
    "    selected_features = list(map(lambda f: int(f[0]), rar.feature_ranking[:i]))\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s, y_train)\n",
    "    scores.loc[i, 'RaR'] = clf_selected.score(X_test_s, y_test)\n",
    "    sys.stdout.write('\\rBenchmark: {}%     '.format(100 * i / (2*max_k)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# DecisionTree\n",
    "for i in range(1,max_k):\n",
    "    clf_selected = ExtraTreesClassifier(max_features=i, n_jobs=-1)\n",
    "    selected_features = [r[0] for r in ranking[:i]]\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s, y_train)\n",
    "    scores.loc[i, 'DecisionTree'] = clf_selected.score(X_test_s, y_test)\n",
    "    sys.stdout.write('\\rBenchmark: {}%     '.format(50 + 100 * i / (2*max_k)))\n",
    "    sys.stdout.flush()\n",
    "print('Benchmark: 100.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-08T12:19:27.588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['DecisionTree'], label='DecisionTree')\n",
    "plt.plot(scores['RaR'], label='RaR')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('test4_FS_ExtraTrees_Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In case we need to look at the tree\n",
    "from sklearn import tree\n",
    "import pydot\n",
    "from sklearn.externals.six import StringIO\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file='tree.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
