{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csrar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Injector_Median100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/test5.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About test2.arff:\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(24860, 25140)  \n",
    "seed=0\n",
    "#### About test3.arff\n",
    "useful=Vector(0, 1)  \n",
    "dependent=Vector(5, 6, 7, 8, 9)  \n",
    "duplicated=Vector((0,12), (4,10), (6,11))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4)]  \n",
    "distribution=List(249786, 250214)  \n",
    "#### About test4.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29)  \n",
    "dependent=Vector(100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149)  \n",
    "duplicated=Vector((7,168), (10,157), (24,159), (28,162), (30,166), (50,169), (61,154), (82,158), (99,167), (104,156), (107,151), (113,164), (117,155), (117,165), (124,150), (135,160), (139,152), (145,161), (146,153), (147,163))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), (10, 11, 12, 13, 14), (15, 16, 17)]  \n",
    "distribution=List(250085, 249915)  \n",
    "#### About test5.arff\n",
    "useful=Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)  \n",
    "dependent=Vector(80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109)  \n",
    "duplicated=Vector((4,118), (8,114), (8,146), (9,137), (9,144), (10,131), (17,123), (22,116), (24,120), (24,142), (25,125), (35,127), (42,119), (43,122), (45,111), (48,134), (50,132), (52,110), (54,138), (57,112), (57,115), (57,149), (62,141), (64,136), (70,117), (70,148), (73,126), (76,133), (77,140), (78,143), (83,113), (84,139), (91,145), (92,121), (93,128), (93,135), (95,124), (103,129), (104,130), (105,147))  \n",
    "nominal=List()  \n",
    "clusters=[(0, 1, 2), (3, 4), (5, 6, 7, 8, 9, 10, 11, 12, 13, 14)]  \n",
    "distribution=List(99718, 100282)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = 150\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rar_data = pd.concat([X_train, y_train], axis=1)\n",
    "# RaR uses columns with string label only\n",
    "rar_data.rename(columns=lambda c: str(c), inplace=True)\n",
    "target = str(target)\n",
    "rar = csrar.rar.RaR(rar_data)\n",
    "rar.run(target, k=5, runs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranking = []\n",
    "for index, importance in enumerate(clf.feature_importances_):\n",
    "    ranking.append((data.columns[index], importance))\n",
    "ranking.sort(key=lambda r: r[1], reverse=True)\n",
    "for (index, rank) in enumerate(ranking):\n",
    "        print('{}. {} with a score of {}'.format(index + 1, rank[0], rank[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking with top k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_selected = RandomForestClassifier()\n",
    "scores = pd.DataFrame(columns=['RaR', 'Tree'], index=np.arange(40))\n",
    "scores = scores.fillna(0)\n",
    "\n",
    "# RaR\n",
    "for i in range(1,40):\n",
    "    selected_features = list(map(lambda f: int(f[0]), rar.feature_ranking[:i]))\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s, y_train)\n",
    "    scores.loc[i, 'RaR'] = clf_selected.score(X_test_s, y_test)\n",
    "    \n",
    "# ExtraTrees\n",
    "for i in range(1,40):\n",
    "    selected_features = [r[0] for r in ranking[:i]]\n",
    "    X_train_s = X_train[selected_features]\n",
    "    X_test_s = X_test[selected_features]\n",
    "    clf_selected.fit(X_train_s2, y_train)\n",
    "    scores.loc[i, 'Tree'] = clf_selected.score(X_test_s2, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['Tree'], label='Tree')\n",
    "plt.plot(scores['RaR'], label='RaR')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('test5_FS_RandomForest_Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case we need to look at the tree\n",
    "from sklearn import tree\n",
    "import pydot\n",
    "from sklearn.externals.six import StringIO\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file='tree.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
