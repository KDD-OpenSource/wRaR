{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:31:14.876066Z",
     "start_time": "2017-07-19T01:31:14.486670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_wHiCS: 10 datasets, each 100 independent features, 40 of them useful  \n",
    "2_wRaR: 10 datasets, each 30 independent features, 20 of them useful, 70 dependent features  \n",
    "3_wRaR: 10 datasets, each 100 independent features, 50 of them useful, 100 dependent features  \n",
    "5_wrar: 1 dataset, 40 independent features, 25 of them useful, 20 dependent  \n",
    "6_wrar: 3 datasets, 40 independent, 30 useful, 40 dependent  \n",
    "7_wrar: 4 datasets, 40 independent, 30 useful, 40 dependent   \n",
    "8_wrar: 4 datasets, each 30 independent features, 20 of them useful, 70 dependent features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:08:23.099376Z",
     "start_time": "2017-07-19T14:08:21.146652Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datas = []\n",
    "for i in range(1, 11):\n",
    "    X, y = load_svmlight_file('../data/gas_sensor/batch'+ str(i) +'.dat')\n",
    "    data = pd.SparseDataFrame(X).to_dense()\n",
    "    data[128] = y\n",
    "    data[128] = data[128].astype(np.float32)\n",
    "    data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    datas.append(data)\n",
    "target = str(128)\n",
    "data = pd.concat(datas).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:08:26.020302Z",
     "start_time": "2017-07-19T14:08:26.016269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18439971,  0.21035226,  0.11797268,  0.13918045,  0.21631919,\n",
       "        0.1317757 ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data[target], return_counts=True)[1] / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:25:29.680495Z",
     "start_time": "2017-07-19T01:25:29.675162Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = np.array([1/6] * 6)\n",
    "while gini(dist) < 0.4:\n",
    "    dist = np.random.rand(6)\n",
    "dist /= sum(dist)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T02:28:18.928809Z",
     "start_time": "2017-07-19T02:28:18.926020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:08:41.024968Z",
     "start_time": "2017-07-19T14:08:40.996373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37949940061904208"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Artificially imbalance dataset\n",
    "class1 = data.loc[data[target] == 1]\n",
    "class2 = data.loc[data[target] == 2]\n",
    "class3 = data.loc[data[target] == 3]\n",
    "class4 = data.loc[data[target] == 4]\n",
    "class5 = data.loc[data[target] == 5]\n",
    "class6 = data.loc[data[target] == 6]\n",
    "new_dist = [class1.sample(frac=0.2), class2.sample(frac=1), class3.sample(frac=0.6), \n",
    "            class4.sample(frac=1), class5.sample(frac=0.05), class6.sample(frac=1)]\n",
    "imb_data = pd.concat(new_dist).reset_index(drop=True)\n",
    "\n",
    "gini(np.unique(imb_data[target], return_counts=True)[1]/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T02:26:04.712955Z",
     "start_time": "2017-07-19T02:26:04.709510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37949940061904208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(np.unique(imb_data[target], return_counts=True)[1] / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:11:05.958321Z",
     "start_time": "2017-07-19T14:11:05.956080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = imb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:13:31.899296Z",
     "start_time": "2017-07-19T14:13:31.895951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0] * 128\n",
    "len(a[:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:11:29.327093Z",
     "start_time": "2017-07-19T14:11:28.801353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95581431,  0.94242078,  0.95986598])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = imb_data.drop(target, axis=1)\n",
    "y = imb_data[target]\n",
    "\n",
    "clf_all = KNeighborsClassifier(n_neighbors=5)\n",
    "f1_macros = cross_val_score(clf_all, X, y, cv=3, scoring='f1_macro')\n",
    "f1_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T02:45:11.525483Z",
     "start_time": "2017-07-19T02:30:49.405286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated cost matrix:\n",
      "         1.0       2.0       3.0       4.0    5.0       6.0\n",
      "0  16.263158  2.851333  8.470051  4.309401  55.62  4.551555\n",
      "Overall cost matrix:\n",
      "         1.0       2.0       3.0       4.0    5.0       6.0\n",
      "0  16.263158  2.851333  8.470051  4.309401  55.62  4.551555\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'76': 0.1458114307455812, '9': 0.25362513156760752, '3': 0.4135806527907912, '79': 0.34861572332942864, '103': 0.062015106938144174, '45': 0.1545898173635552, '22': 0.18514922870201361, '52': 2.0702069181117487e-10, '119': 2.06887550082813e-10, '18': 0.18460771913938062, '26': 2.079031808010515e-10, '110': 2.0702069181117487e-10, '28': 0.39335141848669003, '13': 0.030750664990789517, '53': 2.0702069181117487e-10, '33': 0.39340851804269733, '120': 2.0933198392977505e-10, '2': 0.034009332586945669, '67': 2.0702069181117487e-10, '59': 2.0702069181117487e-10, '63': 2.0702069181117487e-10, '87': 2.0702069181117487e-10, '23': 2.0702069181117487e-10, '125': 2.0702069181117487e-10, '51': 0.21311351846486146, '61': 2.069437794936311e-10, '47': 2.0847160372762876e-10, '66': 0.0017934221548005468, '54': 0.18689838827790808, '65': 2.0702069181117487e-10, '83': 0.3456942179301839, '56': 0.44922466178251863, '126': 0.30314318241952731, '93': 0.30314318241952504, '113': 0.00057400516676865763, '27': 2.069437794936311e-10, '81': 0.23102814321727685, '5': 0.52626694902206228, '19': 2.0940961428091325e-10, '107': 2.0702069181117487e-10, '62': 0.21411413879666885, '104': 0.43928512807366465, '95': 0.13407905333578563, '100': 0.0020444709770218749, '46': 0.030750664990788493, '43': 0.68328954729198532, '90': 2.0702069181117487e-10, '44': 2.0702069181117487e-10, '4': 0.32270480811864127, '31': 2.0702069181117487e-10, '73': 0.40867443522800023, '42': 0.25640967938346865, '60': 2.0702069181117487e-10, '32': 0.010413937787534067, '40': 0.042931696895891172, '74': 0.073270274256172108, '109': 2.0702069181117487e-10, '21': 2.0702069181117487e-10, '98': 0.12195658784874647, '34': 0.064994236583058293, '89': 2.0702069181117487e-10, '80': 2.0702069181117487e-10, '121': 2.0702069181117487e-10, '58': 0.064586036682729164, '57': 0.30015090712727288, '117': 2.0702069181117487e-10, '71': 2.0702069181117487e-10, '29': 2.0702069181117487e-10, '108': 0.30015089469748585, '124': 0.20275920403690575, '96': 0.49103452633581446, '14': 2.0702069181117487e-10, '25': 2.0702069181117487e-10, '77': 2.0702069181117487e-10, '111': 0.0073755083324995932, '102': 0.041745368052119723, '24': 0.00057400516676865763, '48': 0.041762602825545773, '12': 0.20011191570595752, '97': 2.0702069181117487e-10, '68': 2.079031808010515e-10, '30': 2.0702069181117487e-10, '91': 2.0702069181117487e-10, '7': 0.74907406840049973, '6': 0.72932932935648787, '101': 0.24243826653313916, '114': 0.015776925881625027, '10': 2.0702069181117487e-10, '39': 0.14194929176879126, '84': 2.0702069181117487e-10, '41': 0.041745368052119765, '55': 0.27132356472500091, '11': 2.0702069181117487e-10, '88': 2.0733237825857378e-10, '106': 0.00057400516676865763, '85': 0.09665443998817641, '112': 2.0702069181117487e-10, '82': 0.12195658784874286, '72': 0.32712850623155693, '17': 0.14194929176879126, '94': 0.022227325184737117, '78': 0.47986327731148737, '35': 2.069437794936311e-10, '69': 0.13521231283196941, '105': 0.24775284806034395, '70': 2.0702069181117487e-10, '1': 0.13913456124742585, '118': 0.099633385517188963, '99': 0.24182266034899505, '86': 0.079781402840036708, '37': 0.30015089469748585, '20': 0.27515473935053747, '8': 0.10905752205855201, '49': 0.015776925881625027, '122': 2.0712039108671061e-10, '38': 2.0702069181117487e-10, '75': 2.0702069181117487e-10, '0': 0.12325325318958726, '64': 0.18795457503757959, '123': 2.0702069181117487e-10, '36': 2.0702069181117487e-10, '92': 0.20011191570595724, '116': 2.0702069181117487e-10, '115': 2.0702069181117487e-10, '16': 0.0073755083435175818, '15': 2.0702069181117487e-10, '127': 2.0702069181117487e-10, '50': 2.0702069181117487e-10})\n",
      "Redundancy: 100.00%    \n",
      "1. 7 with a score of 0.8484716448765869\n",
      "2. 6 with a score of 0.8222639351533351\n",
      "3. 43 with a score of 0.769983469516832\n",
      "4. 5 with a score of 0.6890027134772063\n",
      "5. 96 with a score of 0.6316386079367646\n",
      "6. 78 with a score of 0.6257014169136417\n",
      "7. 104 with a score of 0.5996408216617267\n",
      "8. 73 with a score of 0.5738735336777224\n",
      "9. 3 with a score of 0.5706963081047659\n",
      "10. 56 with a score of 0.5681708986781208\n",
      "11. 33 with a score of 0.5465499649740687\n",
      "12. 28 with a score of 0.5304686216514752\n",
      "13. 79 with a score of 0.501070627418425\n",
      "14. 4 with a score of 0.48509183856374194\n",
      "15. 83 with a score of 0.47884660000875207\n",
      "16. 72 with a score of 0.4777584612710406\n",
      "17. 108 with a score of 0.44852353115818233\n",
      "18. 37 with a score of 0.44777925537676927\n",
      "19. 126 with a score of 0.4436050583505032\n",
      "20. 57 with a score of 0.4358469588175887\n",
      "21. 93 with a score of 0.43555728198880045\n",
      "22. 55 with a score of 0.4197277364488272\n",
      "23. 20 with a score of 0.4156187455027463\n",
      "24. 9 with a score of 0.4011927107331237\n",
      "25. 42 with a score of 0.3988269303761026\n",
      "26. 105 with a score of 0.39215371722651854\n",
      "27. 101 with a score of 0.37678243103167525\n",
      "28. 99 with a score of 0.37622900326302994\n",
      "29. 81 with a score of 0.35721533380194\n",
      "30. 62 with a score of 0.34181204748818217\n",
      "31. 51 with a score of 0.337097139806608\n",
      "32. 12 with a score of 0.32669998672747347\n",
      "33. 124 with a score of 0.32424291262439764\n",
      "34. 92 with a score of 0.32416671155390514\n",
      "35. 64 with a score of 0.30446286042943743\n",
      "36. 18 with a score of 0.3008733611346026\n",
      "37. 22 with a score of 0.3004500266976333\n",
      "38. 54 with a score of 0.29956140840027706\n",
      "39. 45 with a score of 0.2618538775040143\n",
      "40. 76 with a score of 0.2513181841953792\n",
      "41. 39 with a score of 0.2475637949864397\n",
      "42. 1 with a score of 0.24335222184581137\n",
      "43. 17 with a score of 0.24289933635148547\n",
      "44. 69 with a score of 0.23589001607364182\n",
      "45. 95 with a score of 0.23507913596151053\n",
      "46. 0 with a score of 0.2161146774407993\n",
      "47. 98 with a score of 0.21233590376655886\n",
      "48. 82 with a score of 0.21096114206245117\n",
      "49. 8 with a score of 0.19348859096000015\n",
      "50. 118 with a score of 0.17837354005074676\n",
      "51. 85 with a score of 0.17306748827822363\n",
      "52. 86 with a score of 0.14557555577272802\n",
      "53. 74 with a score of 0.13514158170108348\n",
      "54. 34 with a score of 0.12101792970110645\n",
      "55. 58 with a score of 0.11974347459017039\n",
      "56. 103 with a score of 0.11647593041032826\n",
      "57. 40 with a score of 0.0817817786041433\n",
      "58. 41 with a score of 0.07975117727145618\n",
      "59. 102 with a score of 0.07957413481621332\n",
      "60. 48 with a score of 0.07919501735356335\n",
      "61. 2 with a score of 0.06558361090879977\n",
      "62. 13 with a score of 0.05947658485009934\n",
      "63. 46 with a score of 0.05943254417300023\n",
      "64. 94 with a score of 0.043222508990740156\n",
      "65. 49 with a score of 0.0309758814111325\n",
      "66. 114 with a score of 0.030912548713676394\n",
      "67. 32 with a score of 0.02060507580005416\n",
      "68. 111 with a score of 0.014638795048826038\n",
      "69. 16 with a score of 0.014622852734394544\n",
      "70. 100 with a score of 0.004079401334847597\n",
      "71. 66 with a score of 0.0035793434737007453\n",
      "72. 106 with a score of 0.0011472929107836298\n",
      "73. 24 with a score of 0.0011472369619311882\n",
      "74. 113 with a score of 0.0011472262575209992\n",
      "75. 19 with a score of 4.188192284484719e-10\n",
      "76. 120 with a score of 4.186639677495869e-10\n",
      "77. 47 with a score of 4.169432073652836e-10\n",
      "78. 68 with a score of 4.158063615084901e-10\n",
      "79. 26 with a score of 4.15806361493754e-10\n",
      "80. 88 with a score of 4.1466475641410535e-10\n",
      "81. 122 with a score of 4.142407820637181e-10\n",
      "82. 10 with a score of 4.1404138353646445e-10\n",
      "83. 70 with a score of 4.140413835354049e-10\n",
      "84. 25 with a score of 4.140413835344693e-10\n",
      "85. 65 with a score of 4.140413835341894e-10\n",
      "86. 97 with a score of 4.140413835341396e-10\n",
      "87. 36 with a score of 4.140413835338868e-10\n",
      "88. 23 with a score of 4.140413835338315e-10\n",
      "89. 14 with a score of 4.1404138353315614e-10\n",
      "90. 44 with a score of 4.1404138353299975e-10\n",
      "91. 15 with a score of 4.140413835326512e-10\n",
      "92. 11 with a score of 4.1404138353165636e-10\n",
      "93. 67 with a score of 4.140413835309604e-10\n",
      "94. 87 with a score of 4.140413835309312e-10\n",
      "95. 71 with a score of 4.14041383530493e-10\n",
      "96. 31 with a score of 4.140413835297098e-10\n",
      "97. 38 with a score of 4.1404138352860825e-10\n",
      "98. 127 with a score of 4.140413835277682e-10\n",
      "99. 107 with a score of 4.140413835240881e-10\n",
      "100. 75 with a score of 4.1404138352338e-10\n",
      "101. 84 with a score of 4.1404138352299914e-10\n",
      "102. 63 with a score of 4.1404138352290753e-10\n",
      "103. 109 with a score of 4.140413835226483e-10\n",
      "104. 89 with a score of 4.1404138352210356e-10\n",
      "105. 90 with a score of 4.140413835211079e-10\n",
      "106. 52 with a score of 4.1404138352063293e-10\n",
      "107. 77 with a score of 4.1404138352035505e-10\n",
      "108. 80 with a score of 4.1404138351972035e-10\n",
      "109. 53 with a score of 4.1404138351863095e-10\n",
      "110. 30 with a score of 4.140413835185896e-10\n",
      "111. 110 with a score of 4.1404138351838817e-10\n",
      "112. 50 with a score of 4.1404138351789703e-10\n",
      "113. 91 with a score of 4.1404138351784104e-10\n",
      "114. 112 with a score of 4.140413835170734e-10\n",
      "115. 125 with a score of 4.1404138351573225e-10\n",
      "116. 121 with a score of 4.1404138351508167e-10\n",
      "117. 116 with a score of 4.1404138351501767e-10\n",
      "118. 59 with a score of 4.140413835139161e-10\n",
      "119. 117 with a score of 4.1404138351331704e-10\n",
      "120. 21 with a score of 4.1404138351331513e-10\n",
      "121. 60 with a score of 4.140413835115606e-10\n",
      "122. 123 with a score of 4.140413835094829e-10\n",
      "123. 115 with a score of 4.1404138350532606e-10\n",
      "124. 29 with a score of 4.140413834735211e-10\n",
      "125. 35 with a score of 4.138875588941125e-10\n",
      "126. 27 with a score of 4.138875588908341e-10\n",
      "127. 61 with a score of 4.1388755888417196e-10\n",
      "128. 119 with a score of 4.1377510008002107e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'76': 3.454761604789703e-09, '9': 7.332020621558297e-12, '3': 7.332020621558297e-12, '79': 3.454761604789703e-09, '103': 0.03466660317836839, '45': 1.2301542779671052e-09, '22': 0.009738185366663757, '52': 1.0940629116808534e-11, '119': 7.332020621558297e-12, '18': 6.1251833124908795e-12, '26': 7.023364991120402e-12, '110': 0.30323770688601964, '28': 0.2752699632392775, '13': 0.4060983623856575, '53': 0.3961963163970413, '33': 0.43113222896089587, '120': 1.1098033914516336e-11, '2': 7.332020621558297e-12, '67': 7.332020621558297e-12, '59': 7.332020621558297e-12, '63': 7.332020621558297e-12, '87': 0.6560407623542382, '23': 7.332020621558297e-12, '125': 0.5546050379068003, '51': 0.524574908636744, '61': 0.15242458283765742, '47': 7.56934748017304e-12, '66': 0.6560407623109924, '54': 7.30790255318583e-12, '65': 7.332020621558297e-12, '83': 0.8960985923007451, '56': 0.47466066168620324, '126': 0.6585290107248486, '93': 6.1251833124908795e-12, '113': 7.332020621558297e-12, '27': 1.0, '81': 0.03245672635031078, '5': 7.332020621558297e-12, '19': 7.332020621558297e-12, '107': 6.602784754865109e-08, '62': 7.332020621558297e-12, '104': 0.7517613223800579, '95': 0.23478181289084996, '100': 7.332020621558297e-12, '46': 0.39129830955734557, '43': 7.332020621558297e-12, '90': 0.4037414852710136, '44': 7.659275484889426e-12, '4': 7.332020621558297e-12, '31': 0.14286696988204328, '73': 7.332020621558297e-12, '42': 0.009738185366663456, '60': 0.45975057129128843, '32': 7.332020621558297e-12, '40': 0.4624678037738754, '74': 0.009738185366663774, '109': 0.2373156000275736, '21': 1.0341964239657764e-09, '98': 0.03466660317836839, '34': 0.44587245410727583, '89': 7.332020621558297e-12, '80': 7.56934748017304e-12, '121': 0.00973818536666372, '58': 6.1251833124908795e-12, '57': 7.332020621558297e-12, '117': 0.4544902159344649, '71': 7.332020621558297e-12, '29': 7.332020621558297e-12, '108': 7.332020621558297e-12, '124': 7.332020621558297e-12, '96': 8.85976763090645e-11, '14': 7.332020621558297e-12, '25': 0.12910540169043458, '77': 7.332020621558297e-12, '111': 0.4275115318473905, '102': 7.332020621558297e-12, '24': 7.861638197624155e-12, '48': 7.193176114919667e-10, '12': 0.42751153188521135, '97': 6.308309585647304e-10, '68': 1.0940629116808534e-11, '30': 7.332020621558297e-12, '91': 0.11428207273975188, '7': 0.18180869914070993, '6': 7.332020621558297e-12, '101': 7.332020621558297e-12, '114': 0.8120012952581998, '10': 7.332020621558297e-12, '39': 7.661608701712201e-12, '84': 0.1830417932012399, '41': 0.25527344673066144, '55': 1.2560098790134558e-11, '11': 0.21601169823778593, '88': 0.5783552978735188, '106': 7.332020621558297e-12, '85': 1.0940629116808534e-11, '112': 7.023364991120402e-12, '82': 7.332020621558297e-12, '72': 6.037344076037337e-12, '17': 7.332020621558297e-12, '94': 7.332020621558297e-12, '78': 7.332020621558297e-12, '35': 7.332020621558297e-12, '69': 0.44587245415005505, '105': 8.633246918020563e-12, '70': 7.332020621558297e-12, '1': 7.332020621558297e-12, '118': 7.332020621558297e-12, '99': 0.5245749086789662, '86': 7.332020621558297e-12, '37': 1.0869131860666521e-11, '20': 0.6426789853209246, '8': 7.332020621558297e-12, '49': 0.18527608005525587, '122': 7.332020621558297e-12, '38': 0.6656338369071846, '75': 7.481041145584456e-12, '0': 7.332020621558297e-12, '64': 0.4037414852710136, '123': 7.332020621558297e-12, '36': 7.332020621558297e-12, '92': 2.344463493528651e-11, '116': 7.023364991120402e-12, '115': 7.332020621558297e-12, '16': 0.22143770402308321, '15': 0.2246923170546854, '127': 6.590298181981057e-12, '50': 6.35801912672918e-12})\n",
      "Redundancy: 100.00%    \n",
      "1. 27 with a score of 0.8933842659447575\n",
      "2. 83 with a score of 0.8474566459445035\n",
      "3. 104 with a score of 0.8124841792670626\n",
      "4. 114 with a score of 0.8055416723759428\n",
      "5. 87 with a score of 0.775122350970885\n",
      "6. 38 with a score of 0.758541043661764\n",
      "7. 20 with a score of 0.7263171468447077\n",
      "8. 66 with a score of 0.7225731024287824\n",
      "9. 126 with a score of 0.7194277316929137\n",
      "10. 88 with a score of 0.6595912579585111\n",
      "11. 125 with a score of 0.6548900494967104\n",
      "12. 99 with a score of 0.6469622012607827\n",
      "13. 51 with a score of 0.6207869247831056\n",
      "14. 40 with a score of 0.611010922948141\n",
      "15. 69 with a score of 0.6043982443999524\n",
      "16. 56 with a score of 0.5907843320161101\n",
      "17. 60 with a score of 0.5886632954139345\n",
      "18. 117 with a score of 0.5884933109606093\n",
      "19. 34 with a score of 0.5876850529952622\n",
      "20. 111 with a score of 0.5848871481365863\n",
      "21. 33 with a score of 0.58476429937217\n",
      "22. 12 with a score of 0.5845605123686999\n",
      "23. 13 with a score of 0.5509299833621755\n",
      "24. 64 with a score of 0.5437296194529768\n",
      "25. 46 with a score of 0.5381565446663603\n",
      "26. 53 with a score of 0.5353073019934341\n",
      "27. 90 with a score of 0.5350618917353174\n",
      "28. 110 with a score of 0.4431874220666784\n",
      "29. 28 with a score of 0.41691766817735476\n",
      "30. 41 with a score of 0.40262112635682107\n",
      "31. 95 with a score of 0.37402217688504\n",
      "32. 109 with a score of 0.36517913742948427\n",
      "33. 15 with a score of 0.3622921641817531\n",
      "34. 11 with a score of 0.35057552387142743\n",
      "35. 16 with a score of 0.3486370185074756\n",
      "36. 7 with a score of 0.3071310423349621\n",
      "37. 84 with a score of 0.3022607398866325\n",
      "38. 49 with a score of 0.29908572939368644\n",
      "39. 61 with a score of 0.2543948002408689\n",
      "40. 31 with a score of 0.24639617211585868\n",
      "41. 25 with a score of 0.22419004031437204\n",
      "42. 91 with a score of 0.19926024538451523\n",
      "43. 103 with a score of 0.06693444379704526\n",
      "44. 98 with a score of 0.06664224451168843\n",
      "45. 81 with a score of 0.0625165764861055\n",
      "46. 42 with a score of 0.01926817090243549\n",
      "47. 74 with a score of 0.019262986631847213\n",
      "48. 121 with a score of 0.01924674694251889\n",
      "49. 22 with a score of 0.01923976389578345\n",
      "50. 107 with a score of 1.3205568488043558e-07\n",
      "51. 76 with a score of 6.909523183521034e-09\n",
      "52. 79 with a score of 6.909523182894691e-09\n",
      "53. 45 with a score of 2.4603085524279857e-09\n",
      "54. 21 with a score of 2.06839284536591e-09\n",
      "55. 48 with a score of 1.4386352217330082e-09\n",
      "56. 97 with a score of 1.2616619162222424e-09\n",
      "57. 96 with a score of 1.771953526009998e-10\n",
      "58. 92 with a score of 4.6889269869338425e-11\n",
      "59. 55 with a score of 2.5120197579908604e-11\n",
      "60. 120 with a score of 2.21960678287211e-11\n",
      "61. 68 with a score of 2.1881258233364642e-11\n",
      "62. 85 with a score of 2.1881258233320818e-11\n",
      "63. 52 with a score of 2.1881258233313167e-11\n",
      "64. 37 with a score of 2.1738263721051572e-11\n",
      "65. 105 with a score of 1.7266493835881933e-11\n",
      "66. 24 with a score of 1.572327639510237e-11\n",
      "67. 39 with a score of 1.5323217403299537e-11\n",
      "68. 44 with a score of 1.5318550969655686e-11\n",
      "69. 47 with a score of 1.5138694960227743e-11\n",
      "70. 80 with a score of 1.5138694960199622e-11\n",
      "71. 75 with a score of 1.4962082291042548e-11\n",
      "72. 1 with a score of 1.4664041243008268e-11\n",
      "73. 5 with a score of 1.466404124300734e-11\n",
      "74. 71 with a score of 1.4664041243006394e-11\n",
      "75. 14 with a score of 1.466404124300632e-11\n",
      "76. 70 with a score of 1.4664041243004672e-11\n",
      "77. 35 with a score of 1.4664041243004488e-11\n",
      "78. 36 with a score of 1.46640412430044e-11\n",
      "79. 57 with a score of 1.4664041243003463e-11\n",
      "80. 9 with a score of 1.4664041243002814e-11\n",
      "81. 65 with a score of 1.466404124300265e-11\n",
      "82. 8 with a score of 1.4664041243002536e-11\n",
      "83. 23 with a score of 1.4664041243002316e-11\n",
      "84. 63 with a score of 1.4664041243002035e-11\n",
      "85. 100 with a score of 1.466404124300086e-11\n",
      "86. 10 with a score of 1.4664041243000158e-11\n",
      "87. 32 with a score of 1.4664041242999806e-11\n",
      "88. 0 with a score of 1.466404124299952e-11\n",
      "89. 6 with a score of 1.4664041242999153e-11\n",
      "90. 17 with a score of 1.4664041242998772e-11\n",
      "91. 77 with a score of 1.4664041242996555e-11\n",
      "92. 119 with a score of 1.4664041242996552e-11\n",
      "93. 89 with a score of 1.4664041242996106e-11\n",
      "94. 67 with a score of 1.4664041242996054e-11\n",
      "95. 4 with a score of 1.4664041242995518e-11\n",
      "96. 3 with a score of 1.466404124299521e-11\n",
      "97. 78 with a score of 1.4664041242995146e-11\n",
      "98. 106 with a score of 1.4664041242994952e-11\n",
      "99. 2 with a score of 1.4664041242994503e-11\n",
      "100. 108 with a score of 1.4664041242994086e-11\n",
      "101. 73 with a score of 1.4664041242992975e-11\n",
      "102. 101 with a score of 1.4664041242990558e-11\n",
      "103. 29 with a score of 1.4664041242987385e-11\n",
      "104. 62 with a score of 1.4664041242985876e-11\n",
      "105. 43 with a score of 1.466404124298512e-11\n",
      "106. 102 with a score of 1.466404124298496e-11\n",
      "107. 122 with a score of 1.466404124298341e-11\n",
      "108. 30 with a score of 1.4664041242983356e-11\n",
      "109. 113 with a score of 1.4664041242983068e-11\n",
      "110. 86 with a score of 1.466404124298284e-11\n",
      "111. 19 with a score of 1.466404124298105e-11\n",
      "112. 123 with a score of 1.466404124298093e-11\n",
      "113. 118 with a score of 1.4664041242980454e-11\n",
      "114. 94 with a score of 1.466404124297946e-11\n",
      "115. 82 with a score of 1.4664041242978848e-11\n",
      "116. 124 with a score of 1.4664041242978218e-11\n",
      "117. 115 with a score of 1.4664041242977856e-11\n",
      "118. 59 with a score of 1.4664041242976425e-11\n",
      "119. 54 with a score of 1.4615805106248508e-11\n",
      "120. 116 with a score of 1.4046729982126314e-11\n",
      "121. 112 with a score of 1.4046729982120558e-11\n",
      "122. 26 with a score of 1.4046729982084364e-11\n",
      "123. 127 with a score of 1.3180596363874551e-11\n",
      "124. 50 with a score of 1.2716038253355852e-11\n",
      "125. 18 with a score of 1.2250366624905828e-11\n",
      "126. 93 with a score of 1.2250366624897275e-11\n",
      "127. 58 with a score of 1.225036662487772e-11\n",
      "128. 72 with a score of 1.2074688152001774e-11\n"
     ]
    }
   ],
   "source": [
    "import wrar\n",
    "\n",
    "rar = wrar.rar.RaR(data)\n",
    "rar.run(target, k=5, runs=50, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "rar_nocomp = wrar.rar.RaR(data)\n",
    "rar_nocomp.run(target, k=5, runs=50, split_iterations=10, compensate_imbalance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:28:31.228808Z",
     "start_time": "2017-07-19T14:27:26.238655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 513 2926  985 1936  150 1833]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wRaR</th>\n",
       "      <th>RaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.322862</td>\n",
       "      <td>0.342192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.482221</td>\n",
       "      <td>0.612037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.629909</td>\n",
       "      <td>0.458125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647844</td>\n",
       "      <td>0.475090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.496638</td>\n",
       "      <td>0.481259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.510827</td>\n",
       "      <td>0.481408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.669233</td>\n",
       "      <td>0.485117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.671115</td>\n",
       "      <td>0.552043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.555172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.700851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.700851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.751900</td>\n",
       "      <td>0.701050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.751796</td>\n",
       "      <td>0.701488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.752326</td>\n",
       "      <td>0.767536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.752404</td>\n",
       "      <td>0.767673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.801627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.802106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.802106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.857384</td>\n",
       "      <td>0.873724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.950679</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.951810</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.942341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.952700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         wRaR       RaR\n",
       "1    0.322862  0.342192\n",
       "2    0.482221  0.612037\n",
       "3    0.629909  0.458125\n",
       "4    0.647844  0.475090\n",
       "5    0.496638  0.481259\n",
       "6    0.510827  0.481408\n",
       "7    0.669233  0.485117\n",
       "8    0.671115  0.552043\n",
       "9    0.680239  0.555172\n",
       "10   0.751952  0.700851\n",
       "11   0.751952  0.700851\n",
       "12   0.751900  0.701050\n",
       "13   0.751796  0.701488\n",
       "14   0.752326  0.767536\n",
       "15   0.752404  0.767673\n",
       "16   0.857384  0.801627\n",
       "17   0.857384  0.801627\n",
       "18   0.857384  0.801627\n",
       "19   0.857384  0.801627\n",
       "20   0.857384  0.801627\n",
       "21   0.857384  0.801627\n",
       "22   0.857384  0.802106\n",
       "23   0.857384  0.802106\n",
       "24   0.857384  0.873724\n",
       "25   0.857384  0.873724\n",
       "26   0.857384  0.873724\n",
       "27   0.857384  0.873724\n",
       "28   0.857384  0.873724\n",
       "29   0.857384  0.873724\n",
       "30   0.857384  0.873724\n",
       "..        ...       ...\n",
       "99   0.950679  0.940859\n",
       "100  0.950679  0.940859\n",
       "101  0.950679  0.940859\n",
       "102  0.950679  0.940859\n",
       "103  0.950679  0.940859\n",
       "104  0.950679  0.940859\n",
       "105  0.950679  0.940859\n",
       "106  0.950679  0.940859\n",
       "107  0.950679  0.940859\n",
       "108  0.951810  0.940859\n",
       "109  0.951810  0.940859\n",
       "110  0.951810  0.940859\n",
       "111  0.951810  0.940859\n",
       "112  0.951810  0.940859\n",
       "113  0.951810  0.940859\n",
       "114  0.952700  0.940859\n",
       "115  0.952700  0.940859\n",
       "116  0.952700  0.940859\n",
       "117  0.952700  0.940859\n",
       "118  0.952700  0.940859\n",
       "119  0.952700  0.940859\n",
       "120  0.952700  0.940859\n",
       "121  0.952700  0.942341\n",
       "122  0.952700  0.942341\n",
       "123  0.952700  0.942341\n",
       "124  0.952700  0.942341\n",
       "125  0.952700  0.942341\n",
       "126  0.952700  0.942341\n",
       "127  0.952700  0.942341\n",
       "128  0.952700  0.952700\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Train/Test split\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# nm = RandomOverSampler(random_state=45622)\n",
    "# X_res, y_res = nm.fit_sample(X, y)\n",
    "\n",
    "# X = pd.DataFrame(X_res, columns=X.columns)\n",
    "# y = y_res\n",
    "\n",
    "print(np.unique(y, return_counts=True)[1])\n",
    "\n",
    "max_k = 128\n",
    "scores = pd.DataFrame(columns=['wRaR', 'RaR'], index=np.arange(1, max_k + 1)).fillna(0)\n",
    "\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for k in range(1, max_k + 1):\n",
    "    # clf = LinearSVC(class_weight='balanced')\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "#     clf = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf, X[rank_columns_nocomp[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'RaR'] = np.mean(f1_macros)\n",
    "\n",
    "    # clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    # y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    # score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "    # scores.loc[k, 'RaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'RaR' + str(i)] += s\n",
    "\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for k in range(1, max_k + 1):\n",
    "    # clf_selected = LinearSVC(class_weight='balanced')\n",
    "    clf_selected = KNeighborsClassifier(n_neighbors=5)\n",
    "#     clf_selected = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf_selected, X[rank_columns[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'wRaR'] = np.mean(f1_macros)\n",
    "    \n",
    "    # clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    # y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    # score = f1_score(y_test, y_predict, average='macro')\n",
    "    # scores.loc[k, 'wRaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "# scores.to_csv('final2_wRaR_gas_nb_3cv.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T14:28:31.363775Z",
     "start_time": "2017-07-19T14:28:31.230457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEdCAYAAADjFntmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJxSgoiIhKnpCAiInH/HzDZryC0nTreAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda71fefef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['RaR'][:50], label='RaR')\n",
    "plt.plot(scores['wRaR'][:50], label='wRaR')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Number of features')\n",
    "ax.set_ylabel(r'Classification Accuracy')\n",
    "ax.set_ylim(0.0)\n",
    "ax.set_xlim(1)\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.savefig('final2_wRaR_gas_5nn_3cv_best50_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T15:41:13.116482Z",
     "start_time": "2017-07-18T15:41:13.087250Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:16.786006Z",
     "start_time": "2017-07-11T15:32:16.763970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test7.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=input_features, index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:01:27.039704Z",
     "start_time": "2017-07-11T16:01:26.981699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test8.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:38:33.508359Z",
     "start_time": "2017-07-11T16:38:33.485332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test9.arff\n",
    "weights = [0.7168886878437233, 0.1650913157879492, 0.7017219042598103, 0.5371651431980248,\n",
    "           0.4012494719087343, 0.08997742462568355, 0.4133240085774441, 0.3003377473503873,\n",
    "           0.12858013417222078, 0.5857996257919974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T00:31:03.912965Z",
     "start_time": "2017-07-19T00:31:00.235147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "datas = []\n",
    "for i in range(1, 4):\n",
    "    file = open('../data/10_wrar/10_wrar_' + str(i) + '.arff', 'r')\n",
    "    dataset = arff.load(file)\n",
    "    file.close()\n",
    "    data = pd.DataFrame(dataset['data'])\n",
    "    data[100] = data[100].astype(np.float32)\n",
    "    data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    datas.append(data)\n",
    "target = str(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:52:39.059210Z",
     "start_time": "2017-07-12T08:52:39.029763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test10.arff\n",
    "weights = [0.2673055187472877, 0.196159223714542, 0.701161636883324, 0.765385125610722,\n",
    "           0.0011260947105074194, 0.22801651296579062, 0.8949526553930152, 0.13072480437597472,\n",
    "           0.6333889311003507, 0.7420344156127076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:70], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:53:11.655906Z",
     "start_time": "2017-07-12T08:53:11.653267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking = ground_truth.sort_values(0, axis=1, ascending=False).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:45:20.511140Z",
     "start_time": "2017-07-12T08:45:20.508965Z"
    }
   },
   "source": [
    "## Compensating HiCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T16:50:52.889691Z",
     "start_time": "2017-07-18T16:50:37.546155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/5_wrar.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data[60] = data[60].astype(np.float32)\n",
    "data.rename(columns=lambda c: str(c), inplace=True)\n",
    "target = str(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standard HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:01:07.693901Z",
     "start_time": "2017-07-12T10:01:07.687405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "X_res = pd.DataFrame(X_res, columns=X_train.columns)\n",
    "# y_res = pd.DataFrame(y_res, columns=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T21:47:33.361286Z",
     "start_time": "2017-07-12T21:47:33.357061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts/len(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T20:04:24.776619Z",
     "start_time": "2017-07-14T20:04:24.455906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "values, counts = np.unique(datas[0][target], return_counts=True)\n",
    "marg = ax.bar(np.arange(5), counts/len(datas[0]), 0.35, color='green')\n",
    "cond = ax.bar(np.arange(5) + 0.35, [0.03, 0.05, 0.7, 0.07, 0.15], 0.35, color='orange')\n",
    "# ax.bar(np.arange(5), counts/len(data), 0.35, color='green')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Marginal and conditional probabilities')\n",
    "ax.set_xticks(np.arange(5) + 0.35 / 2)\n",
    "ax.set_xticklabels(('$c_1$', '$c_2$', '$c_3$', '$c_4$', '$c_5$'))\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax.legend((marg, cond), ('Marginal distribution', 'Conditional distribution'))\n",
    "plt.savefig('marg_cond')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:01:25.817496Z",
     "start_time": "2017-07-18T18:01:25.811517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T11:18:37.320520Z",
     "start_time": "2017-07-18T11:18:37.305589Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T13:18:49.993385Z",
     "start_time": "2017-07-17T13:18:49.971165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in datas:\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    print(counts/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:19:41.849443Z",
     "start_time": "2017-07-17T21:19:41.840916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T18:18:46.261757Z",
     "start_time": "2017-07-12T18:18:42.143869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "results_nocomp = []\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for j in range(25):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    results_nocomp.append(f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "results = []\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for j in range(25):\n",
    "    clf_selected = RandomForestClassifier()\n",
    "    clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "\n",
    "print('Dataset 1_whics_' + str(i+1))#, file=log)\n",
    "print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)))#, file=log)\n",
    "print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)))#, file=log)\n",
    "print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)))#, file=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:42.590702Z",
     "start_time": "2017-07-12T10:18:42.425386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_CG = [ground_truth.loc[0, ideal_ranking[:i].values].sum()\n",
    "            for i in range(len(ideal_ranking))]\n",
    "CG = [ground_truth.loc[0, [r for r in rank_columns[:i]]].sum()\n",
    "      for i in range(len(rank_columns))]\n",
    "nocomp_CG = [ground_truth.loc[0, [r for r in rank_columns_nocomp[:i]]].sum()\n",
    "             for i in range(len(rank_columns_nocomp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:43.542142Z",
     "start_time": "2017-07-12T10:18:43.425054Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(CG, label='Cumulative Gain Compensating HiCS')\n",
    "plt.plot(nocomp_CG, label='Cumulative Gain Standard HiCS')\n",
    "plt.plot(ideal_CG, label='Ideal gain')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.savefig('HiCS_test7_comp_imb2_CG_weightmod1-8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:32.297493Z",
     "start_time": "2017-07-12T10:20:32.287261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns_nocomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:30.514372Z",
     "start_time": "2017-07-12T10:20:30.504454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:50:21.019698Z",
     "start_time": "2017-07-11T16:50:20.946172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T00:28:02.788684Z",
     "start_time": "2017-07-14T00:13:20.765977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = open('binary_wHiCS_log.txt', 'w')\n",
    "for i, data in enumerate(datas):\n",
    "    # Compensating HiCS\n",
    "    #\n",
    "    #\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    cost_matrix = pd.DataFrame(columns=values)\n",
    "    for value, count in zip(values, counts):\n",
    "        weighting = (len(data) / count)\n",
    "        cost_matrix[value] = [weighting]\n",
    "    cost_matrix = cost_matrix\n",
    "    cost_matrix\n",
    "\n",
    "    from hics.result_storage import DefaultResultStorage\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage = DefaultResultStorage(input_features)\n",
    "\n",
    "    from hics.incremental_correlation import IncrementalCorrelation\n",
    "    correlation = IncrementalCorrelation(data, target, storage,\n",
    "                                         iterations=50, alpha=0.1,\n",
    "                                         drop_discrete=False, cost_matrix=cost_matrix)\n",
    "\n",
    "    correlation.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking = storage.get_relevancies().relevancy.sort_values(ascending=False)\n",
    "    rank_columns = [tup[0] for tup in ranking.index.values]\n",
    "\n",
    "    # Standard HiCS\n",
    "    #\n",
    "    #\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage_nocomp = DefaultResultStorage(input_features)\n",
    "    correlation_nocomp = IncrementalCorrelation(data, target, storage_nocomp,\n",
    "                                                iterations=50, alpha=0.1,\n",
    "                                                drop_discrete=False, cost_matrix=None)\n",
    "\n",
    "    correlation_nocomp.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking_nocomp = storage_nocomp.get_relevancies(\n",
    "    ).relevancy.sort_values(ascending=False)\n",
    "    rank_columns_nocomp = [tup[0] for tup in ranking_nocomp.index.values]\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    k = 10\n",
    "    results_nocomp = []\n",
    "    from sklearn.metrics import f1_score\n",
    "    for j in range(100):\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        results_nocomp.append(\n",
    "            f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "    results = []\n",
    "    for j in range(100):\n",
    "        clf_selected = RandomForestClassifier()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "    \n",
    "    print('Dataset 1_whics_' + str(i+1), file=log)\n",
    "    print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)), file=log)\n",
    "    print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)), file=log)\n",
    "    print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)), file=log)\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "max_k = 50\n",
    "classes = np.arange(len(np.unique(datas[0][target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=columns, index=np.arange(1,max_k+1)).fillna(0)\n",
    "\n",
    "for data in datas:\n",
    "    # Compensating RaR\n",
    "    #\n",
    "    #\n",
    "    rar = wrar.rar.RaR(data)\n",
    "    rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Standard RaR\n",
    "    #\n",
    "    #\n",
    "    rar_nocomp = wrar.rar.RaR(data)\n",
    "    rar_nocomp.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=False)\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "    from sklearn.metrics import f1_score\n",
    "    for k in range(1, max_k+1):\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "        scores.loc[k, 'RaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'RaR' + str(i)] += s\n",
    "        \n",
    "    rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "    for k in range(1, max_k+1):\n",
    "        clf_selected = GaussianNB()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        score = f1_score(y_test, y_predict, average='macro')\n",
    "        scores.loc[k, 'wRaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores /= len(datas)\n",
    "scores.to_csv('final_wRaR_3wrar_nb.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T01:31:28.689767Z",
     "start_time": "2017-07-19T01:31:28.684409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        array -= np.amin(array)\n",
    "    array += 0.0000001\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
