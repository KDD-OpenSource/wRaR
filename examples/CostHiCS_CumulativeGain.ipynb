{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:19:01.197210Z",
     "start_time": "2017-07-18T18:19:00.756132Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_wHiCS: 10 datasets, each 100 independent features, 40 of them useful  \n",
    "2_wRaR: 10 datasets, each 30 independent features, 20 of them useful, 70 dependent features  \n",
    "3_wRaR: 10 datasets, each 100 independent features, 50 of them useful, 100 dependent features  \n",
    "5_wrar: 1 dataset, 40 independent features, 25 of them useful, 20 dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:19:07.745753Z",
     "start_time": "2017-07-18T18:19:01.741201Z"
    }
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "datas = []\n",
    "for i in range(1, 11):\n",
    "    file = open('../data/2_wrar/2_wrar_' + str(i) + '.arff', 'r')\n",
    "    dataset = arff.load(file)\n",
    "    file.close()\n",
    "    data = pd.DataFrame(dataset['data'])\n",
    "    data[100] = data[100].astype(np.float32)\n",
    "    data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    datas.append(data)\n",
    "target = str(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:19:07.748620Z",
     "start_time": "2017-07-18T18:19:07.746649Z"
    }
   },
   "outputs": [],
   "source": [
    "data = datas[0] # pd.concat(datas).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:09:23.482753Z",
     "start_time": "2017-07-18T18:09:23.452199Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(data[target], return_counts=True)[1] / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T16:50:52.889691Z",
     "start_time": "2017-07-18T16:50:37.546155Z"
    }
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/5_wrar.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data[60] = data[60].astype(np.float32)\n",
    "data.rename(columns=lambda c: str(c), inplace=True)\n",
    "target = str(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:27:20.428459Z",
     "start_time": "2017-07-18T18:19:14.210264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "Generated cost matrix:\n",
      "         0.0   1.0       2.0        3.0       4.0\n",
      "0  33.112583  20.0  2.352941  14.285714  2.354049\n",
      "Overall cost matrix:\n",
      "         0.0   1.0       2.0        3.0       4.0\n",
      "0  33.112583  20.0  2.352941  14.285714  2.354049\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'34': 7.8025944844157061e-10, '50': 2.7125323781870395e-08, '48': 0.005480551550159295, '75': 0.051204356039098738, '17': 0.28757452654386095, '22': 0.14565231209063337, '21': 0.11041510257520001, '90': 0.022303788440849428, '69': 0.23629167002944704, '98': 0.11021338251552541, '14': 0.38399383545317933, '65': 0.0036306508638446005, '72': 0.22397878739646973, '92': 0.17614782936666556, '56': 0.11749025376951702, '89': 0.17475038397735196, '38': 0.14523466360293941, '31': 9.6002843025621402e-09, '53': 0.049977209324306646, '19': 0.10301132840926468, '54': 0.48682535429727364, '77': 0.093863413308799076, '37': 0.13178069815654686, '1': 0.71375862885954089, '57': 0.10116476903880281, '43': 0.18121873556933368, '51': 0.15619335041630736, '95': 0.01481857427224754, '83': 0.0018564581467167308, '70': 0.24200286875772423, '97': 7.7996816713500955e-10, '61': 0.028013597547368867, '79': 0.25052571769287185, '82': 0.031617500270295376, '55': 0.079725228625227018, '46': 0.0028392970285766581, '91': 0.3617255175876315, '49': 0.33279605089253878, '30': 0.0010001225259449178, '87': 0.16881970047400521, '84': 0.22258078951711441, '78': 0.22625881975226578, '25': 0.084176260236666425, '12': 0.19799218423846313, '60': 0.49779705322899831, '32': 0.040082558317298442, '7': 0.58809747272461854, '28': 0.021074286936650023, '6': 0.75204429983826737, '4': 0.52565609760737553, '67': 0.28450576659653881, '0': 0.55665766731419719, '33': 0.049196142645832337, '15': 0.33284853906911682, '68': 0.13939577502705894, '73': 0.23830936110770318, '71': 0.093762097310152476, '26': 0.2532739077312316, '99': 0.13653528395318867, '9': 0.28499508204929763, '41': 0.26299447864152403, '13': 0.54743678919894934, '10': 0.12553195741408665, '85': 0.15183895469731432, '62': 7.8306295039667218e-10, '81': 0.12153097209045803, '23': 0.081639342609197529, '58': 1.6173942411833976e-06, '35': 0.023980967391006653, '24': 0.12486227359205378, '80': 0.17734195291573934, '45': 0.00094894115336826071, '40': 0.078606894263588772, '63': 0.026229936574811149, '76': 0.81127458873245251, '94': 7.8578161271608599e-10, '88': 7.8038854111460141e-10, '36': 0.056942807126610977, '11': 7.7994969427078732e-10, '18': 0.28621102311810104, '20': 0.087694209757494299, '74': 0.13923549082513012, '96': 0.38374743035736736, '3': 0.24634229209719158, '93': 0.29922469614784836, '27': 0.12333653180604036, '66': 0.056081186686025589, '59': 0.37857170038370941, '64': 7.8092238248233426e-10, '52': 0.0058978149252599246, '5': 0.42619111592016934, '2': 0.1119513217815644, '42': 0.12361400795778149, '44': 0.10123909729961446, '8': 0.52542466361109452, '86': 0.045707935650796325, '47': 0.2665307704709069, '29': 1.5705159717613863e-09, '39': 0.49835104510536815, '16': 0.2151918095990272})\n",
      "Redundancy: 100.00%    \n",
      "1. 76 with a score of 0.8941160929349834\n",
      "2. 6 with a score of 0.8574651060150604\n",
      "3. 1 with a score of 0.8316741813062603\n",
      "4. 7 with a score of 0.739493022094994\n",
      "5. 0 with a score of 0.7139800282445816\n",
      "6. 13 with a score of 0.706561436743039\n",
      "7. 4 with a score of 0.6881745816933267\n",
      "8. 8 with a score of 0.687980989955588\n",
      "9. 60 with a score of 0.6634015014238904\n",
      "10. 39 with a score of 0.6633035280401541\n",
      "11. 54 with a score of 0.6540352348604963\n",
      "12. 5 with a score of 0.596378166458734\n",
      "13. 14 with a score of 0.5544377869340893\n",
      "14. 96 with a score of 0.5536822522502383\n",
      "15. 59 with a score of 0.5488059774246132\n",
      "16. 91 with a score of 0.5306153196135924\n",
      "17. 15 with a score of 0.4990643456588613\n",
      "18. 49 with a score of 0.4982603469424928\n",
      "19. 93 with a score of 0.46020328070350586\n",
      "20. 17 with a score of 0.4463156326721438\n",
      "21. 18 with a score of 0.44473945065021664\n",
      "22. 9 with a score of 0.4429906971595839\n",
      "23. 67 with a score of 0.4424033148088143\n",
      "24. 47 with a score of 0.4203993071498901\n",
      "25. 41 with a score of 0.41592498788799026\n",
      "26. 26 with a score of 0.4038798282696616\n",
      "27. 79 with a score of 0.40014653706754505\n",
      "28. 3 with a score of 0.3949704065399616\n",
      "29. 70 with a score of 0.3893777640874254\n",
      "30. 73 with a score of 0.3845064173285243\n",
      "31. 69 with a score of 0.38182269871483226\n",
      "32. 78 with a score of 0.36858764025084845\n",
      "33. 72 with a score of 0.365683614831578\n",
      "34. 84 with a score of 0.3638208862532226\n",
      "35. 16 with a score of 0.3539567110730601\n",
      "36. 12 with a score of 0.3301940485637879\n",
      "37. 43 with a score of 0.30648867393772766\n",
      "38. 80 with a score of 0.30103948281401355\n",
      "39. 92 with a score of 0.2993760062791994\n",
      "40. 89 with a score of 0.2972491289041526\n",
      "41. 87 with a score of 0.28867436598317364\n",
      "42. 51 with a score of 0.2700294538522151\n",
      "43. 85 with a score of 0.26349824894930524\n",
      "44. 22 with a score of 0.25409100668055357\n",
      "45. 38 with a score of 0.2534831686958442\n",
      "46. 68 with a score of 0.24447526263520128\n",
      "47. 74 with a score of 0.24433423662095755\n",
      "48. 99 with a score of 0.24011852105385834\n",
      "49. 37 with a score of 0.2327856437372797\n",
      "50. 10 with a score of 0.22299011516811323\n",
      "51. 24 with a score of 0.2219314180790926\n",
      "52. 42 with a score of 0.21990236349850661\n",
      "53. 27 with a score of 0.2194743880715141\n",
      "54. 81 with a score of 0.21657550716809346\n",
      "55. 56 with a score of 0.2101463243049559\n",
      "56. 2 with a score of 0.20129423648291572\n",
      "57. 21 with a score of 0.19876485202581495\n",
      "58. 98 with a score of 0.19844948507833066\n",
      "59. 19 with a score of 0.18672811813857806\n",
      "60. 44 with a score of 0.1837033721998215\n",
      "61. 57 with a score of 0.1835768751759367\n",
      "62. 77 with a score of 0.17156378423331106\n",
      "63. 71 with a score of 0.17140044364138707\n",
      "64. 20 with a score of 0.1611794592547402\n",
      "65. 25 with a score of 0.15523820007788908\n",
      "66. 23 with a score of 0.15089506854070459\n",
      "67. 55 with a score of 0.14762562995928424\n",
      "68. 40 with a score of 0.14563394611989852\n",
      "69. 36 with a score of 0.10772320546114418\n",
      "70. 66 with a score of 0.1061539753682841\n",
      "71. 75 with a score of 0.09740016319636549\n",
      "72. 53 with a score of 0.09516748137382255\n",
      "73. 33 with a score of 0.09375451003393283\n",
      "74. 86 with a score of 0.08736405154180059\n",
      "75. 32 with a score of 0.07705870021575624\n",
      "76. 82 with a score of 0.06128515022092096\n",
      "77. 61 with a score of 0.05449462751741944\n",
      "78. 63 with a score of 0.05111119169179486\n",
      "79. 35 with a score of 0.04683287568534556\n",
      "80. 90 with a score of 0.04363073421413119\n",
      "81. 28 with a score of 0.04127664034771109\n",
      "82. 95 with a score of 0.02920166921103032\n",
      "83. 52 with a score of 0.011726276253343066\n",
      "84. 48 with a score of 0.01090116330912693\n",
      "85. 65 with a score of 0.007234944028571017\n",
      "86. 46 with a score of 0.005662493049991683\n",
      "87. 83 with a score of 0.003705997796790561\n",
      "88. 30 with a score of 0.001998238180149791\n",
      "89. 45 with a score of 0.0018960773010374765\n",
      "90. 58 with a score of 3.2347832213007356e-06\n",
      "91. 50 with a score of 5.4250646081950094e-08\n",
      "92. 31 with a score of 1.9200568419911752e-08\n",
      "93. 29 with a score of 3.1410319385827172e-09\n",
      "94. 94 with a score of 1.5715632241918835e-09\n",
      "95. 62 with a score of 1.5661258995649055e-09\n",
      "96. 64 with a score of 1.5618447637425201e-09\n",
      "97. 88 with a score of 1.5607770810096048e-09\n",
      "98. 34 with a score of 1.5605188956638979e-09\n",
      "99. 97 with a score of 1.559936333051759e-09\n",
      "100. 11 with a score of 1.5598993873249315e-09\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "defaultdict(<class 'int'>, {'34': 0.17285689353598785, '50': 2.2357192060184154e-08, '48': 8.247547461370253e-11, '75': 0.4823539107492545, '17': 8.246256268928993e-11, '22': 0.05210996974307586, '21': 0.14463848098518245, '90': 0.8477112609819532, '69': 0.5352352402072553, '98': 0.2591851435392042, '14': 0.2591851461527589, '65': 0.17031262583650342, '72': 0.38125917695059974, '92': 0.5512839502216887, '56': 0.16344915035051574, '89': 8.229407153063515e-11, '38': 0.5081577390599471, '31': 0.1273668751393556, '53': 0.4578275913751099, '19': 8.587762350114781e-11, '54': 0.8477112605286728, '77': 0.9068742198122371, '37': 0.16344914962736742, '1': 0.15595511405142615, '57': 0.20271481133680005, '43': 0.1554043497576508, '51': 9.622836741755999e-08, '95': 0.5617404355863439, '83': 0.030345101004516175, '70': 0.8053539107605392, '97': 8.248069373602761e-11, '61': 0.48077649237579234, '79': 0.1554043482911168, '82': 0.173732439700307, '55': 0.07456757980588063, '46': 0.14860067833666277, '91': 0.1804417613996256, '49': 0.624789606137522, '30': 0.24155355637305678, '87': 8.248590736275228e-11, '84': 0.5081577395404792, '78': 0.3227369276762779, '25': 0.20935280295329364, '12': 0.06263856744083653, '60': 8.251152989103913e-11, '32': 0.05661906921116598, '7': 0.2082813682056384, '28': 0.103985723194977, '6': 0.5825699924177448, '4': 0.5122743829465386, '67': 0.4244015398872529, '0': 0.2690828348685661, '33': 8.232242569064859e-11, '15': 0.8611910991199773, '68': 8.239024117001051e-11, '73': 0.14937374849708637, '71': 0.21815382666514607, '26': 0.07767142067463999, '99': 8.247640120492883e-11, '9': 0.15595521001164672, '41': 8.229660126952924e-11, '13': 0.05425463082574499, '10': 8.309749180003461e-11, '85': 0.16236295310784016, '62': 0.33751363986228733, '81': 0.6502772565997803, '23': 0.20758365952665997, '58': 8.248500549611271e-11, '35': 0.030345035944874282, '24': 0.10984501330269437, '80': 0.05661906638498655, '45': 0.13338917337025916, '40': 8.693162138747288e-11, '63': 2.4244533686389155e-08, '76': 0.4578276672913315, '94': 0.20435907921623378, '88': 0.20271501038695622, '36': 0.4798115630208393, '11': 8.249485623631815e-11, '18': 0.5825699874347814, '20': 8.246256268928993e-11, '74': 0.030345004113614786, '96': 0.9687245374246343, '3': 0.12029949981906551, '93': 0.07456757151119463, '27': 0.535235150242126, '66': 0.3804318581184601, '59': 0.8965605555709553, '64': 0.24150542135048644, '52': 0.8074607432038249, '5': 0.6797452226360989, '2': 0.43265565528170985, '42': 0.4578275811769033, '44': 0.4244015347899515, '8': 1.0, '86': 0.16236295577956747, '47': 0.06263831992788109, '29': 0.16344915425630788, '39': 0.415502944951241, '16': 0.3005687548897874})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundancy: 100.00%    \n",
      "1. 8 with a score of 0.9979759113409086\n",
      "2. 96 with a score of 0.9796281446237727\n",
      "3. 77 with a score of 0.9475472790039866\n",
      "4. 59 with a score of 0.9424452936120544\n",
      "5. 15 with a score of 0.9234275025625519\n",
      "6. 90 with a score of 0.9158584114997939\n",
      "7. 54 with a score of 0.9138149720362415\n",
      "8. 52 with a score of 0.8914579396484753\n",
      "9. 70 with a score of 0.8909640353329557\n",
      "10. 5 with a score of 0.8081550659621576\n",
      "11. 81 with a score of 0.7868497472976457\n",
      "12. 49 with a score of 0.7669266569150341\n",
      "13. 18 with a score of 0.7351623449485011\n",
      "14. 6 with a score of 0.7350697218343142\n",
      "15. 95 with a score of 0.7178241778222\n",
      "16. 92 with a score of 0.7086479049327885\n",
      "17. 27 with a score of 0.6962588531951557\n",
      "18. 69 with a score of 0.6962540410957753\n",
      "19. 4 with a score of 0.6766143940668141\n",
      "20. 84 with a score of 0.672725995227656\n",
      "21. 38 with a score of 0.6722773781541651\n",
      "22. 75 with a score of 0.6496340121724694\n",
      "23. 61 with a score of 0.6479084867466629\n",
      "24. 36 with a score of 0.64729039835092\n",
      "25. 42 with a score of 0.6270742140318539\n",
      "26. 76 with a score of 0.6270623749595413\n",
      "27. 53 with a score of 0.626688315820152\n",
      "28. 2 with a score of 0.6035672711751576\n",
      "29. 67 with a score of 0.5952464720905463\n",
      "30. 44 with a score of 0.5948782844002799\n",
      "31. 39 with a score of 0.5861717622812012\n",
      "32. 72 with a score of 0.5509983715744783\n",
      "33. 66 with a score of 0.5503912953593922\n",
      "34. 62 with a score of 0.5041438803665107\n",
      "35. 78 with a score of 0.48717453825154117\n",
      "36. 16 with a score of 0.461121757780631\n",
      "37. 0 with a score of 0.42360014816781877\n",
      "38. 14 with a score of 0.41145555954760216\n",
      "39. 98 with a score of 0.4112970738238095\n",
      "40. 30 with a score of 0.38883557702088123\n",
      "41. 64 with a score of 0.3886130622006178\n",
      "42. 71 with a score of 0.35774817070295195\n",
      "43. 25 with a score of 0.3459001937863608\n",
      "44. 7 with a score of 0.3445513837363268\n",
      "45. 23 with a score of 0.3435414407533005\n",
      "46. 94 with a score of 0.33882716295876886\n",
      "47. 88 with a score of 0.336823001061032\n",
      "48. 57 with a score of 0.33670914202369717\n",
      "49. 91 with a score of 0.30558506230288474\n",
      "50. 82 with a score of 0.2957911262740612\n",
      "51. 34 with a score of 0.2946096189466056\n",
      "52. 65 with a score of 0.2907128804257938\n",
      "53. 29 with a score of 0.28086740576310437\n",
      "54. 56 with a score of 0.2808221482651768\n",
      "55. 37 with a score of 0.2807497185106497\n",
      "56. 85 with a score of 0.27924732191426266\n",
      "57. 86 with a score of 0.27901785965010345\n",
      "58. 9 with a score of 0.2697028215560841\n",
      "59. 1 with a score of 0.26967922647410497\n",
      "60. 43 with a score of 0.26884372939440754\n",
      "61. 79 with a score of 0.2687721435645286\n",
      "62. 73 with a score of 0.2598006677426819\n",
      "63. 46 with a score of 0.25859890140903286\n",
      "64. 21 with a score of 0.2525991015285406\n",
      "65. 45 with a score of 0.23528268875047564\n",
      "66. 31 with a score of 0.2257209428436912\n",
      "67. 3 with a score of 0.21469744408455513\n",
      "68. 24 with a score of 0.19785608607230515\n",
      "69. 28 with a score of 0.18832720829955363\n",
      "70. 26 with a score of 0.14412155956602649\n",
      "71. 93 with a score of 0.13875295724178727\n",
      "72. 55 with a score of 0.13872848823270095\n",
      "73. 12 with a score of 0.11786951232995403\n",
      "74. 47 with a score of 0.11785688691278258\n",
      "75. 32 with a score of 0.10714777853032213\n",
      "76. 80 with a score of 0.1071379224487014\n",
      "77. 13 with a score of 0.10291001492286855\n",
      "78. 22 with a score of 0.09904208326954282\n",
      "79. 74 with a score of 0.05889951512086761\n",
      "80. 35 with a score of 0.05889793726031334\n",
      "81. 83 with a score of 0.05889319843440096\n",
      "82. 51 with a score of 1.9245671627709485e-07\n",
      "83. 63 with a score of 4.848906619314918e-08\n",
      "84. 50 with a score of 4.4714383117672165e-08\n",
      "85. 40 with a score of 1.7386324275980128e-10\n",
      "86. 19 with a score of 1.7175524698752442e-10\n",
      "87. 10 with a score of 1.6619498358620613e-10\n",
      "88. 60 with a score of 1.6502305976844614e-10\n",
      "89. 11 with a score of 1.6498971245893726e-10\n",
      "90. 87 with a score of 1.649718147118749e-10\n",
      "91. 58 with a score of 1.649700109785621e-10\n",
      "92. 97 with a score of 1.6496138745839527e-10\n",
      "93. 99 with a score of 1.6495280239612468e-10\n",
      "94. 48 with a score of 1.6495094921375012e-10\n",
      "95. 20 with a score of 1.6492512536496283e-10\n",
      "96. 17 with a score of 1.6492512536494642e-10\n",
      "97. 68 with a score of 1.6478048232641235e-10\n",
      "98. 33 with a score of 1.6464485136772206e-10\n",
      "99. 41 with a score of 1.6459320252549892e-10\n",
      "100. 89 with a score of 1.6458814304772565e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wRaR</th>\n",
       "      <th>RaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236240</td>\n",
       "      <td>0.210432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260249</td>\n",
       "      <td>0.216560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257920</td>\n",
       "      <td>0.231701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285476</td>\n",
       "      <td>0.240985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.291875</td>\n",
       "      <td>0.266416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.268082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.288634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.337250</td>\n",
       "      <td>0.294218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.349471</td>\n",
       "      <td>0.312741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.359545</td>\n",
       "      <td>0.314903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.380589</td>\n",
       "      <td>0.319331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.381070</td>\n",
       "      <td>0.329959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.391476</td>\n",
       "      <td>0.331397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.401465</td>\n",
       "      <td>0.342814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.391020</td>\n",
       "      <td>0.338674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.403433</td>\n",
       "      <td>0.346899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.421620</td>\n",
       "      <td>0.349105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.419197</td>\n",
       "      <td>0.353966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.424195</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.445436</td>\n",
       "      <td>0.356420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.440287</td>\n",
       "      <td>0.352567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.444891</td>\n",
       "      <td>0.360643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.455255</td>\n",
       "      <td>0.364028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.454672</td>\n",
       "      <td>0.368141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.447099</td>\n",
       "      <td>0.359370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.446451</td>\n",
       "      <td>0.390991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.448503</td>\n",
       "      <td>0.386685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.458454</td>\n",
       "      <td>0.384010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.467053</td>\n",
       "      <td>0.396344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.464730</td>\n",
       "      <td>0.397889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wRaR       RaR\n",
       "1   0.236240  0.210432\n",
       "2   0.260249  0.216560\n",
       "3   0.257920  0.231701\n",
       "4   0.285476  0.240985\n",
       "5   0.291875  0.266416\n",
       "6   0.307600  0.268082\n",
       "7   0.326879  0.288634\n",
       "8   0.337250  0.294218\n",
       "9   0.349471  0.312741\n",
       "10  0.359545  0.314903\n",
       "11  0.380589  0.319331\n",
       "12  0.381070  0.329959\n",
       "13  0.391476  0.331397\n",
       "14  0.401465  0.342814\n",
       "15  0.391020  0.338674\n",
       "16  0.403433  0.346899\n",
       "17  0.421620  0.349105\n",
       "18  0.419197  0.353966\n",
       "19  0.424195  0.360445\n",
       "20  0.445436  0.356420\n",
       "21  0.440287  0.352567\n",
       "22  0.444891  0.360643\n",
       "23  0.455255  0.364028\n",
       "24  0.454672  0.368141\n",
       "25  0.447099  0.359370\n",
       "26  0.446451  0.390991\n",
       "27  0.448503  0.386685\n",
       "28  0.458454  0.384010\n",
       "29  0.467053  0.396344\n",
       "30  0.464730  0.397889"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb 0\n",
    "import csrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_k = 30\n",
    "classes = np.arange(len(np.unique(data[target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=['wRaR', 'RaR'], index=np.arange(1, max_k + 1)).fillna(0)\n",
    "\n",
    "# Compensating RaR\n",
    "#\n",
    "#\n",
    "rar = csrar.rar.RaR(data)\n",
    "rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "# Standard RaR\n",
    "#\n",
    "#\n",
    "rar_nocomp = csrar.rar.RaR(data)\n",
    "rar_nocomp.run(target, k=5, runs=200, split_iterations=10,\n",
    "               compensate_imbalance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:48:46.714320Z",
     "start_time": "2017-07-18T18:48:32.245513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wRaR</th>\n",
       "      <th>RaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259694</td>\n",
       "      <td>0.191504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285987</td>\n",
       "      <td>0.203374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276159</td>\n",
       "      <td>0.221759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309678</td>\n",
       "      <td>0.234230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.319656</td>\n",
       "      <td>0.260068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.329584</td>\n",
       "      <td>0.259156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.349556</td>\n",
       "      <td>0.257794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.388516</td>\n",
       "      <td>0.255343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.375805</td>\n",
       "      <td>0.285625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.378667</td>\n",
       "      <td>0.295440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.359910</td>\n",
       "      <td>0.302095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.360654</td>\n",
       "      <td>0.296839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.356081</td>\n",
       "      <td>0.290134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.351754</td>\n",
       "      <td>0.290797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.353740</td>\n",
       "      <td>0.284652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.352405</td>\n",
       "      <td>0.302314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.360577</td>\n",
       "      <td>0.302674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.352763</td>\n",
       "      <td>0.286935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.348317</td>\n",
       "      <td>0.285373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.352151</td>\n",
       "      <td>0.288254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.357877</td>\n",
       "      <td>0.285927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.356682</td>\n",
       "      <td>0.283963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.363161</td>\n",
       "      <td>0.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.367363</td>\n",
       "      <td>0.305225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.364283</td>\n",
       "      <td>0.285475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.365576</td>\n",
       "      <td>0.303437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.362987</td>\n",
       "      <td>0.305102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.359848</td>\n",
       "      <td>0.304337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.374648</td>\n",
       "      <td>0.328542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.382673</td>\n",
       "      <td>0.325167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wRaR       RaR\n",
       "1   0.259694  0.191504\n",
       "2   0.285987  0.203374\n",
       "3   0.276159  0.221759\n",
       "4   0.309678  0.234230\n",
       "5   0.319656  0.260068\n",
       "6   0.329584  0.259156\n",
       "7   0.349556  0.257794\n",
       "8   0.388516  0.255343\n",
       "9   0.375805  0.285625\n",
       "10  0.378667  0.295440\n",
       "11  0.359910  0.302095\n",
       "12  0.360654  0.296839\n",
       "13  0.356081  0.290134\n",
       "14  0.351754  0.290797\n",
       "15  0.353740  0.284652\n",
       "16  0.352405  0.302314\n",
       "17  0.360577  0.302674\n",
       "18  0.352763  0.286935\n",
       "19  0.348317  0.285373\n",
       "20  0.352151  0.288254\n",
       "21  0.357877  0.285927\n",
       "22  0.356682  0.283963\n",
       "23  0.363161  0.283621\n",
       "24  0.367363  0.305225\n",
       "25  0.364283  0.285475\n",
       "26  0.365576  0.303437\n",
       "27  0.362987  0.305102\n",
       "28  0.359848  0.304337\n",
       "29  0.374648  0.328542\n",
       "30  0.382673  0.325167"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test split\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Test Classifier\n",
    "#\n",
    "#\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for k in range(1, max_k + 1):\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    f1_macros = cross_val_score(clf, X[rank_columns_nocomp[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'RaR'] = np.mean(f1_macros)\n",
    "\n",
    "    # clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    # y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    # score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "    # scores.loc[k, 'RaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'RaR' + str(i)] += s\n",
    "\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for k in range(1, max_k + 1):\n",
    "    clf_selected = KNeighborsClassifier(n_neighbors=1)\n",
    "    f1_macros = cross_val_score(clf_selected, X[rank_columns[:k]], y, cv=3, scoring='f1_macro')\n",
    "    scores.loc[k, 'wRaR'] = np.mean(f1_macros)\n",
    "    \n",
    "    # clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    # y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    # score = f1_score(y_test, y_predict, average='macro')\n",
    "    # scores.loc[k, 'wRaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "# scores.to_csv('final2_wRaR_2wrar_knn_3cv.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:48:58.517408Z",
     "start_time": "2017-07-18T18:48:58.212511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEdCAYAAAD0NOuvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfLPkYYwxxjdLHsYYY3yz5GGMMca3/wece29fy367+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb52c171c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['RaR'][:30], label='RaR')\n",
    "plt.plot(scores['wRaR'][:30], label='wRaR')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Number of features')\n",
    "ax.set_ylabel(r'Macro-averaged $F_1$ score')\n",
    "ax.set_ylim(0.0)\n",
    "ax.set_xlim(1)\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('final2_wRaR_2wrar_1nn_3cv_best30')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T15:41:13.116482Z",
     "start_time": "2017-07-18T15:41:13.087250Z"
    }
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:12.076949Z",
     "start_time": "2017-07-11T15:32:12.060685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificially imbalance dataset\n",
    "class0 = data.loc[data[target] == 0]\n",
    "class1 = data.loc[data[target] == 1]\n",
    "imb_data = pd.concat([class1.sample(frac=0.02), class0]).reset_index(drop=True)\n",
    "# For perfectly balanced dataset, this will result in a 97.56:2.44 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:16.786006Z",
     "start_time": "2017-07-11T15:32:16.763970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test7.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=input_features, index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:01:27.039704Z",
     "start_time": "2017-07-11T16:01:26.981699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test8.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:38:33.508359Z",
     "start_time": "2017-07-11T16:38:33.485332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test9.arff\n",
    "weights = [0.7168886878437233, 0.1650913157879492, 0.7017219042598103, 0.5371651431980248,\n",
    "           0.4012494719087343, 0.08997742462568355, 0.4133240085774441, 0.3003377473503873,\n",
    "           0.12858013417222078, 0.5857996257919974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:52:39.059210Z",
     "start_time": "2017-07-12T08:52:39.029763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test10.arff\n",
    "weights = [0.2673055187472877, 0.196159223714542, 0.701161636883324, 0.765385125610722,\n",
    "           0.0011260947105074194, 0.22801651296579062, 0.8949526553930152, 0.13072480437597472,\n",
    "           0.6333889311003507, 0.7420344156127076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:70], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:53:11.655906Z",
     "start_time": "2017-07-12T08:53:11.653267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking = ground_truth.sort_values(0, axis=1, ascending=False).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:45:20.511140Z",
     "start_time": "2017-07-12T08:45:20.508965Z"
    }
   },
   "source": [
    "## Compensating HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standard HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:01:07.693901Z",
     "start_time": "2017-07-12T10:01:07.687405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "X_res = pd.DataFrame(X_res, columns=X_train.columns)\n",
    "# y_res = pd.DataFrame(y_res, columns=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T21:47:33.361286Z",
     "start_time": "2017-07-12T21:47:33.357061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts/len(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T20:04:24.776619Z",
     "start_time": "2017-07-14T20:04:24.455906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "values, counts = np.unique(datas[0][target], return_counts=True)\n",
    "marg = ax.bar(np.arange(5), counts/len(datas[0]), 0.35, color='green')\n",
    "cond = ax.bar(np.arange(5) + 0.35, [0.03, 0.05, 0.7, 0.07, 0.15], 0.35, color='orange')\n",
    "# ax.bar(np.arange(5), counts/len(data), 0.35, color='green')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Marginal and conditional probabilities')\n",
    "ax.set_xticks(np.arange(5) + 0.35 / 2)\n",
    "ax.set_xticklabels(('$c_1$', '$c_2$', '$c_3$', '$c_4$', '$c_5$'))\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax.legend((marg, cond), ('Marginal distribution', 'Conditional distribution'))\n",
    "plt.savefig('marg_cond')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:01:25.817496Z",
     "start_time": "2017-07-18T18:01:25.811517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T11:18:37.320520Z",
     "start_time": "2017-07-18T11:18:37.305589Z"
    }
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T13:18:49.993385Z",
     "start_time": "2017-07-17T13:18:49.971165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in datas:\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    print(counts/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:19:41.849443Z",
     "start_time": "2017-07-17T21:19:41.840916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T18:18:46.261757Z",
     "start_time": "2017-07-12T18:18:42.143869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "results_nocomp = []\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for j in range(25):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    results_nocomp.append(f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "results = []\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for j in range(25):\n",
    "    clf_selected = RandomForestClassifier()\n",
    "    clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "\n",
    "print('Dataset 1_whics_' + str(i+1))#, file=log)\n",
    "print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)))#, file=log)\n",
    "print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)))#, file=log)\n",
    "print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)))#, file=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:42.590702Z",
     "start_time": "2017-07-12T10:18:42.425386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_CG = [ground_truth.loc[0, ideal_ranking[:i].values].sum()\n",
    "            for i in range(len(ideal_ranking))]\n",
    "CG = [ground_truth.loc[0, [r for r in rank_columns[:i]]].sum()\n",
    "      for i in range(len(rank_columns))]\n",
    "nocomp_CG = [ground_truth.loc[0, [r for r in rank_columns_nocomp[:i]]].sum()\n",
    "             for i in range(len(rank_columns_nocomp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:43.542142Z",
     "start_time": "2017-07-12T10:18:43.425054Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(CG, label='Cumulative Gain Compensating HiCS')\n",
    "plt.plot(nocomp_CG, label='Cumulative Gain Standard HiCS')\n",
    "plt.plot(ideal_CG, label='Ideal gain')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.savefig('HiCS_test7_comp_imb2_CG_weightmod1-8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:32.297493Z",
     "start_time": "2017-07-12T10:20:32.287261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns_nocomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:30.514372Z",
     "start_time": "2017-07-12T10:20:30.504454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:50:21.019698Z",
     "start_time": "2017-07-11T16:50:20.946172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T00:28:02.788684Z",
     "start_time": "2017-07-14T00:13:20.765977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = open('binary_wHiCS_log.txt', 'w')\n",
    "for i, data in enumerate(datas):\n",
    "    # Compensating HiCS\n",
    "    #\n",
    "    #\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    cost_matrix = pd.DataFrame(columns=values)\n",
    "    for value, count in zip(values, counts):\n",
    "        weighting = (len(data) / count)\n",
    "        cost_matrix[value] = [weighting]\n",
    "    cost_matrix = cost_matrix\n",
    "    cost_matrix\n",
    "\n",
    "    from hics.result_storage import DefaultResultStorage\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage = DefaultResultStorage(input_features)\n",
    "\n",
    "    from hics.incremental_correlation import IncrementalCorrelation\n",
    "    correlation = IncrementalCorrelation(data, target, storage,\n",
    "                                         iterations=50, alpha=0.1,\n",
    "                                         drop_discrete=False, cost_matrix=cost_matrix)\n",
    "\n",
    "    correlation.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking = storage.get_relevancies().relevancy.sort_values(ascending=False)\n",
    "    rank_columns = [tup[0] for tup in ranking.index.values]\n",
    "\n",
    "    # Standard HiCS\n",
    "    #\n",
    "    #\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage_nocomp = DefaultResultStorage(input_features)\n",
    "    correlation_nocomp = IncrementalCorrelation(data, target, storage_nocomp,\n",
    "                                                iterations=50, alpha=0.1,\n",
    "                                                drop_discrete=False, cost_matrix=None)\n",
    "\n",
    "    correlation_nocomp.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking_nocomp = storage_nocomp.get_relevancies(\n",
    "    ).relevancy.sort_values(ascending=False)\n",
    "    rank_columns_nocomp = [tup[0] for tup in ranking_nocomp.index.values]\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    k = 10\n",
    "    results_nocomp = []\n",
    "    from sklearn.metrics import f1_score\n",
    "    for j in range(100):\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        results_nocomp.append(\n",
    "            f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "    results = []\n",
    "    for j in range(100):\n",
    "        clf_selected = RandomForestClassifier()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "    \n",
    "    print('Dataset 1_whics_' + str(i+1), file=log)\n",
    "    print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)), file=log)\n",
    "    print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)), file=log)\n",
    "    print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)), file=log)\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "max_k = 50\n",
    "classes = np.arange(len(np.unique(datas[0][target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=columns, index=np.arange(1,max_k+1)).fillna(0)\n",
    "\n",
    "for data in datas:\n",
    "    # Compensating RaR\n",
    "    #\n",
    "    #\n",
    "    rar = csrar.rar.RaR(data)\n",
    "    rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Standard RaR\n",
    "    #\n",
    "    #\n",
    "    rar_nocomp = csrar.rar.RaR(data)\n",
    "    rar_nocomp.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=False)\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "    from sklearn.metrics import f1_score\n",
    "    for k in range(1, max_k+1):\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "        scores.loc[k, 'RaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'RaR' + str(i)] += s\n",
    "        \n",
    "    rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "    for k in range(1, max_k+1):\n",
    "        clf_selected = GaussianNB()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        score = f1_score(y_test, y_predict, average='macro')\n",
    "        scores.loc[k, 'wRaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores /= len(datas)\n",
    "scores.to_csv('final_wRaR_3wrar_nb.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T18:49:59.216676Z",
     "start_time": "2017-07-18T18:49:59.195217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        array -= np.amin(array)\n",
    "    array += 0.0000001\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
