{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:27:36.236792Z",
     "start_time": "2017-07-17T21:27:35.840228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_wHiCS: 10 datasets, each 100 independent features, 40 of them useful  \n",
    "2_wRaR: 10 datasets, each 30 independent features, 20 of them useful, 70 dependent features  \n",
    "3_wRaR: 10 datasets, each 100 independent features, 50 of them useful, 100 dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:27:48.707936Z",
     "start_time": "2017-07-17T21:27:37.118211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "datas = []\n",
    "for i in range(1, 11):\n",
    "    file = open('../data/4_wrar/4_wrar_' + str(i) + '.arff', 'r')\n",
    "    dataset = arff.load(file)\n",
    "    data = pd.DataFrame(dataset['data'])\n",
    "    data[200] = data[200].astype(np.float32)\n",
    "    data.rename(columns=lambda c: str(c), inplace=True)\n",
    "    datas.append(data)\n",
    "target = str(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T12:06:16.377104Z",
     "start_time": "2017-07-18T12:06:00.476983Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "file = open('../data/5_wrar.arff', 'r')\n",
    "dataset = arff.load(file)\n",
    "data = pd.DataFrame(dataset['data'])\n",
    "data[60] = data[60].astype(np.float32)\n",
    "data.rename(columns=lambda c: str(c), inplace=True)\n",
    "target = str(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-18T13:50:02.696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated cost matrix:\n",
      "        0.0       1.0          2.0        3.0\n",
      "0  1.307301  4.556743  1052.631579  68.212824\n",
      "Overall cost matrix:\n",
      "        0.0       1.0          2.0        3.0\n",
      "0  1.307301  4.556743  1052.631579  68.212824\n",
      "Relevance: 100.00%    \n",
      "Running optimizer...\n",
      "Optimizer done.\n",
      "{'6': 0.03504245039325093, '32': 0.07209567454670966, '18': 0.14586461642497614, '37': 0.06729899632574078, '48': 0.18125887869755677, '46': 0.02780227549392772, '1': 0.3888928873076598, '35': 0.08052161075601011, '39': 0.01711949818428736, '56': 0.034064183822945175, '42': 0.0805911206916858, '13': 0.6049270321797519, '49': 0.04536102651424331, '31': 9.800268938690221e-09, '52': 1.0, '40': 0.181544400788502, '23': 0.043655602768395294, '22': 0.09182361694098688, '14': 0.060416983350696285, '50': 0.09532519111267157, '34': 0.07506010352229832, '41': 0.12366994691225053, '7': 9.78119198088605e-09, '15': 0.21925620051555467, '8': 0.29691711909862345, '12': 0.18115686958500699, '36': 0.017634908260319073, '9': 0.3114106565731153, '43': 0.08941565282578687, '54': 0.22266331749786217, '3': 0.023507325293057397, '28': 9.781762706240876e-09, '4': 0.5087200836477654, '24': 0.05364210762334674, '33': 9.785157730380334e-09, '45': 0.04044583955237979, '5': 0.20729666797650198, '2': 0.08380420939194633, '47': 0.06868233452202717, '0': 0.4096045856345391, '21': 0.18126211767631786, '57': 0.3144798922518457, '10': 0.05116065651362022, '53': 0.18689035598702886, '16': 0.3779179456702489, '17': 0.5416320482304398, '51': 0.06645961522165515, '20': 0.14544651441362053, '30': 0.07467382641590797, '26': 0.18583925500240056, '29': 0.0343735219125706, '27': 0.04579575425453757, '58': 0.1818888573325234, '38': 0.04078752856024216, '25': 0.016906551506872515, '11': 0.08588877280382397, '55': 0.17849611486575637, '19': 0.27607859431291937, '44': 0.06284909432399373, '59': 0.06833339490249676}\n",
      "Redundancy: 43.33%     "
     ]
    }
   ],
   "source": [
    "import csrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "max_k = 50\n",
    "classes = np.arange(len(np.unique(datas[0][target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=['wRaR', 'RaR'], index=np.arange(1, max_k + 1)).fillna(0)\n",
    "\n",
    "# Compensating RaR\n",
    "#\n",
    "#\n",
    "rar = csrar.rar.RaR(data)\n",
    "rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "# Standard RaR\n",
    "#\n",
    "#\n",
    "rar_nocomp = csrar.rar.RaR(data)\n",
    "rar_nocomp.run(target, k=5, runs=200, split_iterations=10,\n",
    "               compensate_imbalance=False)\n",
    "\n",
    "# Train/Test split\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Test Classifier\n",
    "#\n",
    "#\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for k in range(1, max_k + 1):\n",
    "    clf = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf, X, y, cv=10, scoring='f1_macro')\n",
    "    scores.loc[k, 'RaR'] = np.mean(f1_macros)\n",
    "\n",
    "    # clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    # y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    # score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "    # scores.loc[k, 'RaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'RaR' + str(i)] += s\n",
    "\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for k in range(1, max_k + 1):\n",
    "    clf_selected = GaussianNB()\n",
    "    f1_macros = cross_val_score(clf_selected, X, y, cv=10, scoring='f1_macro')\n",
    "    scores.loc[k, 'wRaR'] = np.mean(f1_macros)\n",
    "    \n",
    "    # clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    # y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    # score = f1_score(y_test, y_predict, average='macro')\n",
    "    # scores.loc[k, 'wRaR'] += score\n",
    "    # for i, s in enumerate(score):\n",
    "    #    scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores.to_csv('final_wRaR_5wrar_nb_10cv.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T13:19:09.990224Z",
     "start_time": "2017-07-18T13:19:09.983049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wRaR</th>\n",
       "      <th>RaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wRaR  RaR\n",
       "1      0    0\n",
       "2      0    0\n",
       "3      0    0\n",
       "4      0    0\n",
       "5      0    0\n",
       "6      0    0\n",
       "7      0    0\n",
       "8      0    0\n",
       "9      0    0\n",
       "10     0    0\n",
       "11     0    0\n",
       "12     0    0\n",
       "13     0    0\n",
       "14     0    0\n",
       "15     0    0\n",
       "16     0    0\n",
       "17     0    0\n",
       "18     0    0\n",
       "19     0    0\n",
       "20     0    0\n",
       "21     0    0\n",
       "22     0    0\n",
       "23     0    0\n",
       "24     0    0\n",
       "25     0    0\n",
       "26     0    0\n",
       "27     0    0\n",
       "28     0    0\n",
       "29     0    0\n",
       "30     0    0\n",
       "31     0    0\n",
       "32     0    0\n",
       "33     0    0\n",
       "34     0    0\n",
       "35     0    0\n",
       "36     0    0\n",
       "37     0    0\n",
       "38     0    0\n",
       "39     0    0\n",
       "40     0    0\n",
       "41     0    0\n",
       "42     0    0\n",
       "43     0    0\n",
       "44     0    0\n",
       "45     0    0\n",
       "46     0    0\n",
       "47     0    0\n",
       "48     0    0\n",
       "49     0    0\n",
       "50     0    0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:12.076949Z",
     "start_time": "2017-07-11T15:32:12.060685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Artificially imbalance dataset\n",
    "class0 = data.loc[data[target] == 0]\n",
    "class1 = data.loc[data[target] == 1]\n",
    "imb_data = pd.concat([class1.sample(frac=0.02), class0]).reset_index(drop=True)\n",
    "# For perfectly balanced dataset, this will result in a 97.56:2.44 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T15:32:16.786006Z",
     "start_time": "2017-07-11T15:32:16.763970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test7.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=input_features, index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:01:27.039704Z",
     "start_time": "2017-07-11T16:01:26.981699Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test8.arff\n",
    "weights = [0.5335601544927123, 0.759839177764759, 0.772151052808685, 0.7625265610410171,\n",
    "           0.5612073314384326, 0.34594353279215817, 0.26778115186982904, 0.05104168604756121,\n",
    "           0.24539066769327755, 0.4298986108981449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:38:33.508359Z",
     "start_time": "2017-07-11T16:38:33.485332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test9.arff\n",
    "weights = [0.7168886878437233, 0.1650913157879492, 0.7017219042598103, 0.5371651431980248,\n",
    "           0.4012494719087343, 0.08997742462568355, 0.4133240085774441, 0.3003377473503873,\n",
    "           0.12858013417222078, 0.5857996257919974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:20], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:52:39.059210Z",
     "start_time": "2017-07-12T08:52:39.029763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For test10.arff\n",
    "weights = [0.2673055187472877, 0.196159223714542, 0.701161636883324, 0.765385125610722,\n",
    "           0.0011260947105074194, 0.22801651296579062, 0.8949526553930152, 0.13072480437597472,\n",
    "           0.6333889311003507, 0.7420344156127076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "ground_truth = pd.DataFrame(columns=data.columns[:70], index=[0])\n",
    "ground_truth.iloc[0] = weights\n",
    "# ground_truth.rename(columns=lambda c: int(c), inplace=True)\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:53:11.655906Z",
     "start_time": "2017-07-12T08:53:11.653267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking = ground_truth.sort_values(0, axis=1, ascending=False).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T08:45:20.511140Z",
     "start_time": "2017-07-12T08:45:20.508965Z"
    }
   },
   "source": [
    "## Compensating HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standard HiCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:01:07.693901Z",
     "start_time": "2017-07-12T10:01:07.687405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "X_res = pd.DataFrame(X_res, columns=X_train.columns)\n",
    "# y_res = pd.DataFrame(y_res, columns=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T21:47:33.361286Z",
     "start_time": "2017-07-12T21:47:33.357061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts/len(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T20:04:24.776619Z",
     "start_time": "2017-07-14T20:04:24.455906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "values, counts = np.unique(datas[0][target], return_counts=True)\n",
    "marg = ax.bar(np.arange(5), counts/len(datas[0]), 0.35, color='green')\n",
    "cond = ax.bar(np.arange(5) + 0.35, [0.03, 0.05, 0.7, 0.07, 0.15], 0.35, color='orange')\n",
    "# ax.bar(np.arange(5), counts/len(data), 0.35, color='green')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Marginal and conditional probabilities')\n",
    "ax.set_xticks(np.arange(5) + 0.35 / 2)\n",
    "ax.set_xticklabels(('$c_1$', '$c_2$', '$c_3$', '$c_4$', '$c_5$'))\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax.legend((marg, cond), ('Marginal distribution', 'Conditional distribution'))\n",
    "plt.savefig('marg_cond')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-13T08:57:30.935329Z",
     "start_time": "2017-07-13T08:57:30.929454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T11:18:37.320520Z",
     "start_time": "2017-07-18T11:18:37.305589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RaR</th>\n",
       "      <th>wRaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386124</td>\n",
       "      <td>0.355424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400427</td>\n",
       "      <td>0.392254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.415751</td>\n",
       "      <td>0.400801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.424124</td>\n",
       "      <td>0.405274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.428637</td>\n",
       "      <td>0.408962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.436484</td>\n",
       "      <td>0.415857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.419158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.443431</td>\n",
       "      <td>0.423684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.445162</td>\n",
       "      <td>0.426344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.450587</td>\n",
       "      <td>0.427571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.456955</td>\n",
       "      <td>0.436025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.461167</td>\n",
       "      <td>0.437135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.466843</td>\n",
       "      <td>0.438829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.463554</td>\n",
       "      <td>0.441155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.467660</td>\n",
       "      <td>0.441422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.474253</td>\n",
       "      <td>0.449417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.475053</td>\n",
       "      <td>0.450472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.478145</td>\n",
       "      <td>0.452761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.482125</td>\n",
       "      <td>0.453390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.484267</td>\n",
       "      <td>0.457230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.486449</td>\n",
       "      <td>0.456311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.485235</td>\n",
       "      <td>0.457882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.489702</td>\n",
       "      <td>0.462450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.492579</td>\n",
       "      <td>0.463411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.492716</td>\n",
       "      <td>0.465516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.467730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.494531</td>\n",
       "      <td>0.470384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.493978</td>\n",
       "      <td>0.472832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.493228</td>\n",
       "      <td>0.474803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.496480</td>\n",
       "      <td>0.475985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.498627</td>\n",
       "      <td>0.475382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.498212</td>\n",
       "      <td>0.477485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.499833</td>\n",
       "      <td>0.481386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.479658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.503895</td>\n",
       "      <td>0.480279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.502726</td>\n",
       "      <td>0.481556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.503755</td>\n",
       "      <td>0.483170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.504063</td>\n",
       "      <td>0.483209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.504889</td>\n",
       "      <td>0.484519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.507115</td>\n",
       "      <td>0.484232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.507932</td>\n",
       "      <td>0.482425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.510236</td>\n",
       "      <td>0.483003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.511644</td>\n",
       "      <td>0.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.515671</td>\n",
       "      <td>0.486160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.516360</td>\n",
       "      <td>0.487015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.515399</td>\n",
       "      <td>0.486921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.516950</td>\n",
       "      <td>0.489585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.516817</td>\n",
       "      <td>0.491071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.517066</td>\n",
       "      <td>0.492199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.518281</td>\n",
       "      <td>0.491660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RaR      wRaR\n",
       "1   0.386124  0.355424\n",
       "2   0.400427  0.392254\n",
       "3   0.415751  0.400801\n",
       "4   0.424124  0.405274\n",
       "5   0.428637  0.408962\n",
       "6   0.436484  0.415857\n",
       "7   0.439664  0.419158\n",
       "8   0.443431  0.423684\n",
       "9   0.445162  0.426344\n",
       "10  0.450587  0.427571\n",
       "11  0.456955  0.436025\n",
       "12  0.461167  0.437135\n",
       "13  0.466843  0.438829\n",
       "14  0.463554  0.441155\n",
       "15  0.467660  0.441422\n",
       "16  0.474253  0.449417\n",
       "17  0.475053  0.450472\n",
       "18  0.478145  0.452761\n",
       "19  0.482125  0.453390\n",
       "20  0.484267  0.457230\n",
       "21  0.486449  0.456311\n",
       "22  0.485235  0.457882\n",
       "23  0.489702  0.462450\n",
       "24  0.492579  0.463411\n",
       "25  0.492716  0.465516\n",
       "26  0.493865  0.467730\n",
       "27  0.494531  0.470384\n",
       "28  0.493978  0.472832\n",
       "29  0.493228  0.474803\n",
       "30  0.496480  0.475985\n",
       "31  0.498627  0.475382\n",
       "32  0.498212  0.477485\n",
       "33  0.499833  0.481386\n",
       "34  0.500347  0.479658\n",
       "35  0.503895  0.480279\n",
       "36  0.502726  0.481556\n",
       "37  0.503755  0.483170\n",
       "38  0.504063  0.483209\n",
       "39  0.504889  0.484519\n",
       "40  0.507115  0.484232\n",
       "41  0.507932  0.482425\n",
       "42  0.510236  0.483003\n",
       "43  0.511644  0.485500\n",
       "44  0.515671  0.486160\n",
       "45  0.516360  0.487015\n",
       "46  0.515399  0.486921\n",
       "47  0.516950  0.489585\n",
       "48  0.516817  0.491071\n",
       "49  0.517066  0.492199\n",
       "50  0.518281  0.491660"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T13:18:49.993385Z",
     "start_time": "2017-07-17T13:18:49.971165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in datas:\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    print(counts/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T21:19:41.849443Z",
     "start_time": "2017-07-17T21:19:41.840916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T11:47:39.835357Z",
     "start_time": "2017-07-18T11:47:39.645687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEdCAYAAAD0NOuvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns+u+7YI8EgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff88fd0b4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores['RaR'][:50], label='RaR')\n",
    "plt.plot(scores['wRaR'][:50], label='wRaR')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Number of features')\n",
    "ax.set_ylabel(r'Macro-averaged $F_1$ score')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.savefig('final_wRaR_3wrar_nb_best50')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T18:18:46.261757Z",
     "start_time": "2017-07-12T18:18:42.143869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "results_nocomp = []\n",
    "rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "from sklearn.metrics import f1_score\n",
    "for j in range(25):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "    y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "    results_nocomp.append(f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "results = []\n",
    "rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "for j in range(25):\n",
    "    clf_selected = RandomForestClassifier()\n",
    "    clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "    y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "    results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "\n",
    "print('Dataset 1_whics_' + str(i+1))#, file=log)\n",
    "print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)))#, file=log)\n",
    "print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)))#, file=log)\n",
    "print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)))#, file=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:42.590702Z",
     "start_time": "2017-07-12T10:18:42.425386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_CG = [ground_truth.loc[0, ideal_ranking[:i].values].sum()\n",
    "            for i in range(len(ideal_ranking))]\n",
    "CG = [ground_truth.loc[0, [r for r in rank_columns[:i]]].sum()\n",
    "      for i in range(len(rank_columns))]\n",
    "nocomp_CG = [ground_truth.loc[0, [r for r in rank_columns_nocomp[:i]]].sum()\n",
    "             for i in range(len(rank_columns_nocomp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:18:43.542142Z",
     "start_time": "2017-07-12T10:18:43.425054Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(CG, label='Cumulative Gain Compensating HiCS')\n",
    "plt.plot(nocomp_CG, label='Cumulative Gain Standard HiCS')\n",
    "plt.plot(ideal_CG, label='Ideal gain')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "# plt.savefig('HiCS_test7_comp_imb2_CG_weightmod1-8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:32.297493Z",
     "start_time": "2017-07-12T10:20:32.287261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns_nocomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T10:20:30.514372Z",
     "start_time": "2017-07-12T10:20:30.504454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T16:50:21.019698Z",
     "start_time": "2017-07-11T16:50:20.946172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T00:28:02.788684Z",
     "start_time": "2017-07-14T00:13:20.765977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = open('binary_wHiCS_log.txt', 'w')\n",
    "for i, data in enumerate(datas):\n",
    "    # Compensating HiCS\n",
    "    #\n",
    "    #\n",
    "    values, counts = np.unique(data[target], return_counts=True)\n",
    "    cost_matrix = pd.DataFrame(columns=values)\n",
    "    for value, count in zip(values, counts):\n",
    "        weighting = (len(data) / count)\n",
    "        cost_matrix[value] = [weighting]\n",
    "    cost_matrix = cost_matrix\n",
    "    cost_matrix\n",
    "\n",
    "    from hics.result_storage import DefaultResultStorage\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage = DefaultResultStorage(input_features)\n",
    "\n",
    "    from hics.incremental_correlation import IncrementalCorrelation\n",
    "    correlation = IncrementalCorrelation(data, target, storage,\n",
    "                                         iterations=50, alpha=0.1,\n",
    "                                         drop_discrete=False, cost_matrix=cost_matrix)\n",
    "\n",
    "    correlation.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking = storage.get_relevancies().relevancy.sort_values(ascending=False)\n",
    "    rank_columns = [tup[0] for tup in ranking.index.values]\n",
    "\n",
    "    # Standard HiCS\n",
    "    #\n",
    "    #\n",
    "    input_features = [ft for ft in data.columns.values if ft != target]\n",
    "    storage_nocomp = DefaultResultStorage(input_features)\n",
    "    correlation_nocomp = IncrementalCorrelation(data, target, storage_nocomp,\n",
    "                                                iterations=50, alpha=0.1,\n",
    "                                                drop_discrete=False, cost_matrix=None)\n",
    "\n",
    "    correlation_nocomp.update_bivariate_relevancies(runs=5)\n",
    "\n",
    "    ranking_nocomp = storage_nocomp.get_relevancies(\n",
    "    ).relevancy.sort_values(ascending=False)\n",
    "    rank_columns_nocomp = [tup[0] for tup in ranking_nocomp.index.values]\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    k = 10\n",
    "    results_nocomp = []\n",
    "    from sklearn.metrics import f1_score\n",
    "    for j in range(100):\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        results_nocomp.append(\n",
    "            f1_score(y_test, y_predict_ideal, average='macro'))\n",
    "\n",
    "    results = []\n",
    "    for j in range(100):\n",
    "        clf_selected = RandomForestClassifier()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        results.append(f1_score(y_test, y_predict, average='macro'))\n",
    "    \n",
    "    print('Dataset 1_whics_' + str(i+1), file=log)\n",
    "    print('Weighted RaR macro-weighted F1: ' + str(np.mean(results)), file=log)\n",
    "    print('Standard RaR macro-weighted F1: ' + str(np.mean(results_nocomp)), file=log)\n",
    "    print('Difference weighted-standard: ' + str(np.mean(results) - np.mean(results_nocomp)), file=log)\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csrar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "max_k = 50\n",
    "classes = np.arange(len(np.unique(datas[0][target])))\n",
    "columns = ['RaR' + str(i) for i in classes] + ['wRaR' + str(i) for i in classes]\n",
    "scores = pd.DataFrame(columns=columns, index=np.arange(1,max_k+1)).fillna(0)\n",
    "\n",
    "for data in datas:\n",
    "    # Compensating RaR\n",
    "    #\n",
    "    #\n",
    "    rar = csrar.rar.RaR(data)\n",
    "    rar.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=True)\n",
    "\n",
    "    # Standard RaR\n",
    "    #\n",
    "    #\n",
    "    rar_nocomp = csrar.rar.RaR(data)\n",
    "    rar_nocomp.run(target, k=5, runs=200, split_iterations=10, compensate_imbalance=False)\n",
    "\n",
    "    # Train/Test split\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Test Classifier\n",
    "    #\n",
    "    #\n",
    "    rank_columns_nocomp = [r[0] for r in rar_nocomp.feature_ranking]\n",
    "    from sklearn.metrics import f1_score\n",
    "    for k in range(1, max_k+1):\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train[rank_columns_nocomp[:k]], y_train)\n",
    "        y_predict_ideal = clf.predict(X_test[rank_columns_nocomp[:k]])\n",
    "        score = f1_score(y_test, y_predict_ideal, average='macro')\n",
    "        scores.loc[k, 'RaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'RaR' + str(i)] += s\n",
    "        \n",
    "    rank_columns = [r[0] for r in rar.feature_ranking]\n",
    "    for k in range(1, max_k+1):\n",
    "        clf_selected = GaussianNB()\n",
    "        clf_selected.fit(X_train[rank_columns[:k]], y_train)\n",
    "        y_predict = clf_selected.predict(X_test[rank_columns[:k]])\n",
    "        score = f1_score(y_test, y_predict, average='macro')\n",
    "        scores.loc[k, 'wRaR'] += score\n",
    "        for i, s in enumerate(score):\n",
    "            scores.loc[k, 'wRaR' + str(i)] += s\n",
    "\n",
    "scores /= len(datas)\n",
    "scores.to_csv('final_wRaR_3wrar_nb.csv')\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
